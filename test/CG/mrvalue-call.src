// R %srcc --ir --target x86_64-unknown-linux %s
program test;

proc p_in (in $T) {}
proc p_out (out $T) {}
proc p_inout (inout $T) {}
proc p_copy (copy $T) {}
proc p_move ($T) {}

// SRValue.
proc srvalue {
    var i = 1;
    var j = "123";
    p_in(1);
    p_copy(1);
    p_move(1);

    p_in(i);
    p_copy(i);
    p_move(i);

    p_in("123");
    p_copy("123");
    p_move("123");

    p_in(j);
    p_copy(j);
    p_move(j);

    p_inout(i);
    p_out(i);

    p_inout(j);
    p_out(j);
}

// Small MRValue.
proc mrvalue_small {
    struct small { int i; }
    var s = small(1);

    p_in(small(1));
    p_copy(small(1));
    p_move(small(1));

    p_in(small(s));
    p_copy(small(s));
    p_move(small(s));

    p_inout(s);
    p_out(s);
}

// Large MRValue.
proc mrvalue_large {
    struct large { int[100] i; }
    var l = large();

    p_in(large());
    p_copy(large());
    p_move(large());

    p_in(l);
    p_copy(l);
    p_move(l);

    p_inout(l);
    p_out(l);
}

// * @0 = "123\00"
// +
// + proc __src_assert_fail (ptr) external fastcc;
// +
// + proc __src_int_arith_error (ptr) external fastcc;
// +
// + proc __src_main external fastcc {
// + entry:
// +     ret
// + }
// +
// + proc _S7srvalueFvE private fastcc {
// +     #0 = 8, align 8
// +     #1 = 16, align 8
// +
// + entry:
// +     store #0, i64 1, align 8
// +     store #1, ptr @0, align 8
// +     %0 = ptradd #1, 8
// +     store %0, i64 3, align 8
// +     call fastcc void _S4p_inFvxiE(i64 1)
// +     call fastcc void _S6p_copyFvx3iE(i64 1)
// +     call fastcc void _S6p_moveFviE(i64 1)
// +     %1 = load i64, #0, align 8
// +     call fastcc void _S4p_inFvxiE(i64 %1)
// +     %2 = load i64, #0, align 8
// +     call fastcc void _S6p_copyFvx3iE(i64 %2)
// +     %3 = load i64, #0, align 8
// +     call fastcc void _S6p_moveFviE(i64 %3)
// +     call fastcc void _S4p_inFvxSI8E(ptr @0, i64 3)
// +     call fastcc void _S6p_copyFvx3SI8E(ptr @0, i64 3)
// +     call fastcc void _S6p_moveFvSI8E(ptr @0, i64 3)
// +     %4 = load ptr, #1, align 8
// +     %5 = ptradd #1, 8
// +     %6 = load i64, %5, align 8
// +     call fastcc void _S4p_inFvxSI8E(ptr %4, i64 %6)
// +     %7 = load ptr, #1, align 8
// +     %8 = ptradd #1, 8
// +     %9 = load i64, %8, align 8
// +     call fastcc void _S6p_copyFvx3SI8E(ptr %7, i64 %9)
// +     %10 = load ptr, #1, align 8
// +     %11 = ptradd #1, 8
// +     %12 = load i64, %11, align 8
// +     call fastcc void _S6p_moveFvSI8E(ptr %10, i64 %12)
// +     call fastcc void _S7p_inoutFvx2iE(ptr #0 dereferenceable 8)
// +     call fastcc void _S5p_outFvx1iE(ptr #0 dereferenceable 8)
// +     call fastcc void _S7p_inoutFvx2SI8E(ptr #1 dereferenceable 16)
// +     call fastcc void _S5p_outFvx1SI8E(ptr #1 dereferenceable 16)
// +     ret
// + }
// +
// + proc _S4p_inFvxiE (i64 %0) private fastcc {
// +     #0 = 8, align 8
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     ret
// + }
// +
// + proc _S6p_copyFvx3iE (i64 %0) private fastcc {
// +     #0 = 8, align 8
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     ret
// + }
// +
// + proc _S6p_moveFviE (i64 %0) private fastcc {
// +     #0 = 8, align 8
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     ret
// + }
// +
// + proc _S4p_inFvxSI8E (ptr %0, i64 %1) private fastcc {
// +     #0 = 16, align 8
// +
// + entry:
// +     store #0, ptr %0, align 8
// +     %2 = ptradd #0, 8
// +     store %2, i64 %1, align 8
// +     ret
// + }
// +
// + proc _S6p_copyFvx3SI8E (ptr %0, i64 %1) private fastcc {
// +     #0 = 16, align 8
// +
// + entry:
// +     store #0, ptr %0, align 8
// +     %2 = ptradd #0, 8
// +     store %2, i64 %1, align 8
// +     ret
// + }
// +
// + proc _S6p_moveFvSI8E (ptr %0, i64 %1) private fastcc {
// +     #0 = 16, align 8
// +
// + entry:
// +     store #0, ptr %0, align 8
// +     %2 = ptradd #0, 8
// +     store %2, i64 %1, align 8
// +     ret
// + }
// +
// + proc _S7p_inoutFvx2iE (ptr %0 dereferenceable 8) private fastcc {
// + entry:
// +     ret
// + }
// +
// + proc _S5p_outFvx1iE (ptr %0 dereferenceable 8) private fastcc {
// + entry:
// +     ret
// + }
// +
// + proc _S7p_inoutFvx2SI8E (ptr %0 dereferenceable 16) private fastcc {
// + entry:
// +     ret
// + }
// +
// + proc _S5p_outFvx1SI8E (ptr %0 dereferenceable 16) private fastcc {
// + entry:
// +     ret
// + }
// +
// + proc _S13mrvalue_smallFvE private fastcc {
// +     #0 = 8, align 8
// +     #1 = 8, align 8
// +     #2 = 8, align 8
// +     #3 = 8, align 8
// +     #4 = 8, align 8
// +     #5 = 8, align 8
// +     #6 = 8, align 8
// +
// + entry:
// +     store #0, i64 1, align 8
// +     store #1, i64 1, align 8
// +     %0 = load i64, #1, align 8
// +     call fastcc void _S4p_inFvxT5smallE(i64 %0)
// +     store #2, i64 1, align 8
// +     %1 = load i64, #2, align 8
// +     call fastcc void _S6p_copyFvx3T5smallE(i64 %1)
// +     store #3, i64 1, align 8
// +     %2 = load i64, #3, align 8
// +     call fastcc void _S6p_moveFvT5smallE(i64 %2)
// +     copy #4 <- #0, 8
// +     %3 = load i64, #4, align 8
// +     call fastcc void _S4p_inFvxT5smallE(i64 %3)
// +     copy #5 <- #0, 8
// +     %4 = load i64, #5, align 8
// +     call fastcc void _S6p_copyFvx3T5smallE(i64 %4)
// +     copy #6 <- #0, 8
// +     %5 = load i64, #6, align 8
// +     call fastcc void _S6p_moveFvT5smallE(i64 %5)
// +     call fastcc void _S7p_inoutFvx2T5smallE(ptr #0 dereferenceable 8)
// +     call fastcc void _S5p_outFvx1T5smallE(ptr #0 dereferenceable 8)
// +     ret
// + }
// +
// + proc _S4p_inFvxT5smallE (i64 %0) private fastcc {
// +     #0 = 8, align 8
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     ret
// + }
// +
// + proc _S6p_copyFvx3T5smallE (i64 %0) private fastcc {
// +     #0 = 8, align 8
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     ret
// + }
// +
// + proc _S6p_moveFvT5smallE (i64 %0) private fastcc {
// +     #0 = 8, align 8
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     ret
// + }
// +
// + proc _S7p_inoutFvx2T5smallE (ptr %0 dereferenceable 8) private fastcc {
// + entry:
// +     ret
// + }
// +
// + proc _S5p_outFvx1T5smallE (ptr %0 dereferenceable 8) private fastcc {
// + entry:
// +     ret
// + }
// +
// + proc _S13mrvalue_largeFvE private fastcc {
// +     #0 = 800, align 8
// +     #1 = 800, align 8
// +     #2 = 800, align 8
// +     #3 = 800, align 8
// +     #4 = 800, align 8
// +     #5 = 800, align 8
// +     #6 = 800, align 8
// +
// + entry:
// +     set ptr #0, i8 0, i64 800
// +     set ptr #1, i8 0, i64 800
// +     call fastcc void _S4p_inFvxT5largeE(ptr #1 dereferenceable 800)
// +     set ptr #2, i8 0, i64 800
// +     call fastcc void _S6p_copyFvx3T5largeE(ptr #2 byval i8[800])
// +     set ptr #3, i8 0, i64 800
// +     call fastcc void _S6p_moveFvT5largeE(ptr #3 byval i8[800])
// +     copy #4 <- #0, 800
// +     call fastcc void _S4p_inFvxT5largeE(ptr #4 dereferenceable 800)
// +     copy #5 <- #0, 800
// +     call fastcc void _S6p_copyFvx3T5largeE(ptr #5 byval i8[800])
// +     copy #6 <- #0, 800
// +     call fastcc void _S6p_moveFvT5largeE(ptr #6 byval i8[800])
// +     call fastcc void _S7p_inoutFvx2T5largeE(ptr #0 dereferenceable 800)
// +     call fastcc void _S5p_outFvx1T5largeE(ptr #0 dereferenceable 800)
// +     ret
// + }
// +
// + proc _S4p_inFvxT5largeE (ptr %0 dereferenceable 800) private fastcc {
// + entry:
// +     ret
// + }
// +
// + proc _S6p_copyFvx3T5largeE (ptr %0 byval i8[800]) private fastcc {
// + entry:
// +     ret
// + }
// +
// + proc _S6p_moveFvT5largeE (ptr %0 byval i8[800]) private fastcc {
// + entry:
// +     ret
// + }
// +
// + proc _S7p_inoutFvx2T5largeE (ptr %0 dereferenceable 800) private fastcc {
// + entry:
// +     ret
// + }
// +
// + proc _S5p_outFvx1T5largeE (ptr %0 dereferenceable 800) private fastcc {
// + entry:
// +     ret
// + }
