// R %srcc --ir --short-filenames --target x86_64-unknown-linux %s
program test;

proc sink (in int) {}
proc exp (in int a, in int b) {
    sink(a ** b);
    sink(a ** b);
    sink(a ** b);
}

proc exp_ass (copy int a, in int b) {
    a **= b;
}

// * @0 = "*\00"
// + @1 = "integer overflow\00"
// + @2 = "-\00"
// + @3 = "preamble.src\00"
// + @4 = "exp >= 0\00"
// + @5 = "attempting to raise 0 to a negative power\00"
// +
// + proc __src_assert_fail (ptr) external fastcc;
// +
// + proc __src_int_arith_error (ptr) external fastcc;
// +
// + proc __src_main external fastcc {
// + entry:
// +     ret
// + }
// +
// + proc _S4sinkFvxiE (i64 %0) private fastcc {
// +     #0 = 8, align 8
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     ret
// + }
// +
// + proc _S3expFvxixiE (i64 %0, i64 %1) private fastcc {
// +     #0 = 8, align 8
// +     #1 = 8, align 8
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     store #1, i64 %1, align 8
// +     %2 = load i64, #0, align 8
// +     %3 = load i64, #1, align 8
// +     %4 = call fastcc i64 _S$2**Fixix3iE(i64 %2, i64 %3)
// +     call fastcc void _S4sinkFvxiE(i64 %4)
// +     %5 = load i64, #0, align 8
// +     %6 = load i64, #1, align 8
// +     %7 = call fastcc i64 _S$2**Fixix3iE(i64 %5, i64 %6)
// +     call fastcc void _S4sinkFvxiE(i64 %7)
// +     %8 = load i64, #0, align 8
// +     %9 = load i64, #1, align 8
// +     %10 = call fastcc i64 _S$2**Fixix3iE(i64 %8, i64 %9)
// +     call fastcc void _S4sinkFvxiE(i64 %10)
// +     ret
// + }
// +
// + proc _S$2**Fixix3iE (i64 %0, i64 %1) private fastcc -> i64 {
// +     #0 = 8, align 8
// +     #1 = 8, align 8
// +     #2 = 8, align 8
// +     #3 = 64, align 8
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     store #1, i64 %1, align 8
// +     %2 = load i64, #1, align 8
// +     %3 = icmp eq i64 %2, 0
// +     br %3 to bb1 else bb2
// +
// + bb1:
// +     ret i64 1
// +
// + bb2:
// +     %4 = load i64, #0, align 8
// +     %5 = icmp eq i64 %4, 0
// +     br %5 to bb3 else bb6
// +
// + bb3:
// +     %6 = load i64, #1, align 8
// +     %7 = icmp sge i64 %6, 0
// +     br %7 to bb5 else bb4
// +
// + bb4:
// +     store #3, ptr @3, align 8
// +     %8 = ptradd #3, 8
// +     store %8, i64 12, align 8
// +     %9 = ptradd #3, 16
// +     store %9, i64 10, align 8
// +     %10 = ptradd #3, 24
// +     store %10, i64 9, align 8
// +     %11 = ptradd #3, 32
// +     store %11, ptr @4, align 8
// +     %12 = ptradd %11, 8
// +     store %12, i64 8, align 8
// +     %13 = ptradd #3, 48
// +     store %13, ptr @5, align 8
// +     %14 = ptradd %13, 8
// +     store %14, i64 41, align 8
// +     abort at loc("preamble.src":10:9) assert(ptr #3)
// +
// + bb5:
// +     ret i64 0
// +
// + bb6:
// +     %15 = load i64, #1, align 8
// +     %16 = icmp slt i64 %15, 0
// +     br %16 to bb7 else bb10
// +
// + bb7:
// +     %17 = load i64, #0, align 8
// +     %18 = icmp eq i64 %17, -1
// +     br %18 to bb8 else bb9
// +
// + bb8:
// +     %19 = load i64, #1, align 8
// +     %20 = and i64 %19, 1
// +     %21 = icmp ne i64 %20, 0
// +     %22 = select %21, i64 -1, 1
// +     ret i64 %22
// +
// + bb9:
// +     %23 = load i64, #0, align 8
// +     %24 = icmp eq i64 %23, 1
// +     %25 = zext i1 %24 to i64
// +     ret i64 %25
// +
// + bb10:
// +     %26 = load i64, #0, align 8
// +     store #2, i64 %26, align 8
// +     br bb11
// +
// + bb11:
// +     %27 = load i64, #1, align 8
// +     %28 = icmp ne i64 %27, 1
// +     br %28 to bb12 else bb17
// +
// + bb12:
// +     %29 = load i64, #2, align 8
// +     %30 = load i64, #0, align 8
// +     %31 = smul ov i64 %29, %30
// +     br %31:1 to bb13 else bb14
// +
// + bb13:
// +     store #3, ptr @3, align 8
// +     %32 = ptradd #3, 8
// +     store %32, i64 12, align 8
// +     %33 = ptradd #3, 16
// +     store %33, i64 26, align 8
// +     %34 = ptradd #3, 24
// +     store %34, i64 9, align 8
// +     %35 = ptradd #3, 32
// +     store %35, ptr @0, align 8
// +     %36 = ptradd %35, 8
// +     store %36, i64 1, align 8
// +     %37 = ptradd #3, 48
// +     store %37, ptr @1, align 8
// +     %38 = ptradd %37, 8
// +     store %38, i64 16, align 8
// +     abort at loc("preamble.src":26:9) arithmetic(ptr #3)
// +
// + bb14:
// +     store #2, i64 %31:0, align 8
// +     %39 = load i64, #1, align 8
// +     %40 = ssub ov i64 %39, 1
// +     br %40:1 to bb15 else bb16
// +
// + bb15:
// +     store #3, ptr @3, align 8
// +     %41 = ptradd #3, 8
// +     store %41, i64 12, align 8
// +     %42 = ptradd #3, 16
// +     store %42, i64 27, align 8
// +     %43 = ptradd #3, 24
// +     store %43, i64 9, align 8
// +     %44 = ptradd #3, 32
// +     store %44, ptr @2, align 8
// +     %45 = ptradd %44, 8
// +     store %45, i64 1, align 8
// +     %46 = ptradd #3, 48
// +     store %46, ptr @1, align 8
// +     %47 = ptradd %46, 8
// +     store %47, i64 16, align 8
// +     abort at loc("preamble.src":27:9) arithmetic(ptr #3)
// +
// + bb16:
// +     store #1, i64 %40:0, align 8
// +     br bb11
// +
// + bb17:
// +     %48 = load i64, #2, align 8
// +     ret i64 %48
// + }
// +
// + proc _S7exp_assFvx3ixiE (i64 %0, i64 %1) private fastcc {
// +     #0 = 8, align 8
// +     #1 = 8, align 8
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     store #1, i64 %1, align 8
// +     %2 = load i64, #1, align 8
// +     %3 = call fastcc ptr _S$3**=FRix2ixiE(ptr #0 dereferenceable 8, i64 %2)
// +     ret
// + }
// +
// + proc _S$3**=FRix2ixiE (ptr %0 dereferenceable 8, i64 %1) private fastcc -> ptr {
// +     #0 = 8, align 8
// +
// + entry:
// +     store #0, i64 %1, align 8
// +     %2 = load i64, %0, align 8
// +     %3 = load i64, #0, align 8
// +     %4 = call fastcc i64 _S$2**Fixix3iE(i64 %2, i64 %3)
// +     store %0, i64 %4, align 8
// +     ret ptr %0
// + }
