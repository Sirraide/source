// R %srcc --ir --short-filenames %s
program test;

proc sink (in int) {}
proc exp (in int a, in int b) {
    sink(a ** b);
    sink(a ** b);
    sink(a ** b);
}

proc exp_ass (copy int a, in int b) {
    a **= b;
}

// * @0 = "*\00"
// + @1 = "integer overflow\00"
// + @2 = "-\00"
// + @3 = "preamble.src\00"
// + @4 = "exp >= 0\00"
// + @5 = "attempting to raise 0 to a negative power\00"
// +
// + proc __src_assert_fail (ptr) external fastcc;
// +
// + proc __src_int_arith_error (ptr) external fastcc;
// +
// + proc __src_main external fastcc {
// + entry:
// +     ret
// + }
// +
// + proc _S4sinkFvxiE (i64 %0) private fastcc {
// + entry:
// +     ret
// + }
// +
// + proc _S3expFvxixiE (i64 %0, i64 %1) private fastcc {
// + entry:
// +     %2 = call fastcc i64 _S$12__srcc_exp_iFixix3iE(i64 %0, i64 %1)
// +     call fastcc void _S4sinkFvxiE(i64 %2)
// +     %3 = call fastcc i64 _S$12__srcc_exp_iFixix3iE(i64 %0, i64 %1)
// +     call fastcc void _S4sinkFvxiE(i64 %3)
// +     %4 = call fastcc i64 _S$12__srcc_exp_iFixix3iE(i64 %0, i64 %1)
// +     call fastcc void _S4sinkFvxiE(i64 %4)
// +     ret
// + }
// +
// + proc _S$12__srcc_exp_iFixix3iE (i64 %0, i64 %1) private fastcc -> i64 {
// +     #0 = 8, align 8
// +     #1 = 8, align 8
// +     #2 = 64, align 8
// +
// + entry:
// +     store #0, i64 %1, align 8
// +     %2 = load i64, #0, align 8
// +     %3 = icmp eq i64 %2, 0
// +     br %3 to bb1 else bb2
// +
// + bb1:
// +     ret i64 1
// +
// + bb2:
// +     %4 = icmp eq i64 %0, 0
// +     br %4 to bb3 else bb6
// +
// + bb3:
// +     %5 = load i64, #0, align 8
// +     %6 = icmp sge i64 %5, 0
// +     br %6 to bb5 else bb4
// +
// + bb4:
// +     store #2, (ptr, i64) (@3, 12), align 8
// +     %7 = ptradd #2, 16
// +     store %7, i64 11, align 8
// +     %8 = ptradd #2, 24
// +     store %8, i64 9, align 8
// +     %9 = ptradd #2, 32
// +     store %9, (ptr, i64) (@4, 8), align 8
// +     %10 = ptradd #2, 48
// +     store %10, (ptr, i64) (@5, 41), align 8
// +     abort at loc("preamble.src":11:9) assert(ptr #2)
// +
// + bb5:
// +     ret i64 0
// +
// + bb6:
// +     %11 = load i64, #0, align 8
// +     %12 = icmp slt i64 %11, 0
// +     br %12 to bb7 else bb10
// +
// + bb7:
// +     %13 = icmp eq i64 %0, -1
// +     br %13 to bb8 else bb9
// +
// + bb8:
// +     %14 = load i64, #0, align 8
// +     %15 = and i64 %14, 1
// +     %16 = icmp ne i64 %15, 0
// +     %17 = select %16, i64 -1, 1
// +     ret i64 %17
// +
// + bb9:
// +     %18 = icmp eq i64 %0, 1
// +     %19 = zext i1 %18 to i64
// +     ret i64 %19
// +
// + bb10:
// +     store #1, i64 %0, align 8
// +     br bb11
// +
// + bb11:
// +     %20 = load i64, #0, align 8
// +     %21 = icmp ne i64 %20, 1
// +     br %21 to bb12 else bb17
// +
// + bb12:
// +     %22 = load i64, #1, align 8
// +     %23 = smul ov i64 %22, %0
// +     br %23:1 to bb13 else bb14
// +
// + bb13:
// +     store #2, (ptr, i64) (@3, 12), align 8
// +     %24 = ptradd #2, 16
// +     store %24, i64 27, align 8
// +     %25 = ptradd #2, 24
// +     store %25, i64 9, align 8
// +     %26 = ptradd #2, 32
// +     store %26, (ptr, i64) (@0, 1), align 8
// +     %27 = ptradd #2, 48
// +     store %27, (ptr, i64) (@1, 16), align 8
// +     abort at loc("preamble.src":27:9) arithmetic(ptr #2)
// +
// + bb14:
// +     store #1, i64 %23:0, align 8
// +     %28 = load i64, #0, align 8
// +     %29 = ssub ov i64 %28, 1
// +     br %29:1 to bb15 else bb16
// +
// + bb15:
// +     store #2, (ptr, i64) (@3, 12), align 8
// +     %30 = ptradd #2, 16
// +     store %30, i64 28, align 8
// +     %31 = ptradd #2, 24
// +     store %31, i64 9, align 8
// +     %32 = ptradd #2, 32
// +     store %32, (ptr, i64) (@2, 1), align 8
// +     %33 = ptradd #2, 48
// +     store %33, (ptr, i64) (@1, 16), align 8
// +     abort at loc("preamble.src":28:9) arithmetic(ptr #2)
// +
// + bb16:
// +     store #0, i64 %29:0, align 8
// +     br bb11
// +
// + bb17:
// +     %34 = load i64, #1, align 8
// +     ret i64 %34
// + }
// +
// + proc _S7exp_assFvx3ixiE (i64 %0, i64 %1) private fastcc {
// +     #0 = 8, align 8
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     %2 = call fastcc ptr _S$19__srcc_exp_assign_iFRix2ixiE(ptr #0, i64 %1)
// +     ret
// + }
// +
// + proc _S$19__srcc_exp_assign_iFRix2ixiE (ptr %0, i64 %1) private fastcc -> ptr {
// + entry:
// +     %2 = load i64, %0, align 8
// +     %3 = call fastcc i64 _S$12__srcc_exp_iFixix3iE(i64 %2, i64 %1)
// +     store %0, i64 %3, align 8
// +     ret ptr %0
// + }
