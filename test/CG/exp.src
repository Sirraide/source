// R %srcc --ir -fshort-filenames --target x86_64-unknown-linux %s
program test;

proc sink (in int) {}
proc sink (in i8) {}

proc exp (in int a, in int b, in i8 c, in i8 d) {
    sink(a ** b);
    sink(a ** b);
    sink(c ** d);
    sink(c ** d);
}

proc exp_ass (copy int a, in int b, copy i8 c, in i8 d) {
    a **= b;
    c **= d;
}

// * @0 = "attempting to raise 0 to a negative power\00"
// + @1 = "exp >= 0\00"
// + @2 = "__srcc_preamble.src\00"
// + @3 = "-\00"
// + @4 = "integer overflow\00"
// + @5 = "*\00"
// +
// + proc __src_main external ccc {
// + entry:
// +     ret
// + }
// +
// + proc _S4sinkFvxiE.1 (i64 %0) private ccc {
// +     #0 = 8, align 8
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     ret
// + }
// +
// + proc _S4sinkFvxI8E.2 (i8 %0) private ccc {
// +     #0 = 1, align 1
// +
// + entry:
// +     store #0, i8 %0, align 1
// +     ret
// + }
// +
// + proc _S3expFvxixixI8xI8E.3 (
// +     i64 %0,
// +     i64 %1,
// +     i8 %2,
// +     i8 %3,
// + ) private ccc {
// +     #0 = 8, align 8
// +     #1 = 8, align 8
// +     #2 = 1, align 1
// +     #3 = 1, align 1
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     store #1, i64 %1, align 8
// +     store #2, i8 %2, align 1
// +     store #3, i8 %3, align 1
// +     %4 = load i64, #0, align 8
// +     %5 = load i64, #1, align 8
// +     %6 = call ccc i64 _S$2**Fixix3iE(i64 %4, i64 %5)
// +     call ccc void _S4sinkFvxiE.1(i64 %6)
// +     %7 = load i64, #0, align 8
// +     %8 = load i64, #1, align 8
// +     %9 = call ccc i64 _S$2**Fixix3iE(i64 %7, i64 %8)
// +     call ccc void _S4sinkFvxiE.1(i64 %9)
// +     %10 = load i8, #2, align 1
// +     %11 = load i8, #3, align 1
// +     %12 = call ccc i8 _S$2**FI8xI8x3I8E(i8 %10, i8 %11)
// +     call ccc void _S4sinkFvxI8E.2(i8 %12)
// +     %13 = load i8, #2, align 1
// +     %14 = load i8, #3, align 1
// +     %15 = call ccc i8 _S$2**FI8xI8x3I8E(i8 %13, i8 %14)
// +     call ccc void _S4sinkFvxI8E.2(i8 %15)
// +     ret
// + }
// +
// + proc _S$2**Fixix3iE (i64 %0, i64 %1) private ccc -> i64 {
// +     #0 = 8, align 8
// +     #1 = 8, align 8
// +     #2 = 8, align 8
// +     #3 = 80, align 8
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     store #1, i64 %1, align 8
// +     %2 = load i64, #1, align 8
// +     %3 = icmp eq i64 %2, 0
// +     br %3 to bb16(1) else bb1
// +
// + bb1:
// +     %4 = load i64, #0, align 8
// +     %5 = icmp eq i64 %4, 0
// +     br %5 to bb2 else bb4
// +
// + bb2:
// +     %6 = load i64, #1, align 8
// +     %7 = icmp sge i64 %6, 0
// +     br %7 to bb16(0) else bb3
// +
// + bb3:
// +     abort at loc("__srcc_preamble.src":16:9) assert(ptr #3)
// +
// + bb4:
// +     %17 = load i64, #1, align 8
// +     %18 = icmp slt i64 %17, 0
// +     br %18 to bb5 else bb8
// +
// + bb5:
// +     %19 = load i64, #0, align 8
// +     %20 = icmp eq i64 %19, -1
// +     br %20 to bb6 else bb7
// +
// + bb6:
// +     %21 = load i64, #1, align 8
// +     %22 = and i64 %21, 1
// +     %23 = icmp ne i64 %22, 0
// +     br %23 to bb16(-1) else bb16(1)
// +
// + bb7:
// +     %24 = load i64, #0, align 8
// +     %25 = icmp eq i64 %24, 1
// +     br %25 to bb16(1) else bb16(0)
// +
// + bb8:
// +     %26 = load i64, #0, align 8
// +     store #2, i64 %26, align 8
// +     br bb9
// +
// + bb9:
// +     %27 = load i64, #1, align 8
// +     %28 = icmp ne i64 %27, 1
// +     br %28 to bb10 else bb15
// +
// + bb10:
// +     %29 = load i64, #2, align 8
// +     %30 = load i64, #0, align 8
// +     %31 = smul ov i64 %29, %30
// +     br %31:1 to bb11 else bb12
// +
// + bb11:
// +     abort at loc("__srcc_preamble.src":34:13) arithmetic(ptr #3)
// +
// + bb12:
// +     store #2, i64 %31:0, align 8
// +     %41 = load i64, #1, align 8
// +     %42 = ssub ov i64 %41, 1
// +     br %42:1 to bb13 else bb14
// +
// + bb13:
// +     abort at loc("__srcc_preamble.src":35:13) arithmetic(ptr #3)
// +
// + bb14:
// +     store #1, i64 %42:0, align 8
// +     br bb9
// +
// + bb15:
// +     %52 = load i64, #2, align 8
// +     br bb16(%52)
// +
// + bb16(i64 %53):
// +     ret i64 %53
// + }
// +
// + proc _S$2**FI8xI8x3I8E (i8 %0, i8 %1) private ccc -> i8 {
// +     #0 = 1, align 1
// +     #1 = 1, align 1
// +     #2 = 1, align 1
// +     #3 = 80, align 8
// +
// + entry:
// +     store #0, i8 %0, align 1
// +     store #1, i8 %1, align 1
// +     %2 = load i8, #1, align 1
// +     %3 = icmp eq i8 %2, 0
// +     br %3 to bb16(1) else bb1
// +
// + bb1:
// +     %4 = load i8, #0, align 1
// +     %5 = icmp eq i8 %4, 0
// +     br %5 to bb2 else bb4
// +
// + bb2:
// +     %6 = load i8, #1, align 1
// +     %7 = icmp sge i8 %6, 0
// +     br %7 to bb16(0) else bb3
// +
// + bb3:
// +     abort at loc("__srcc_preamble.src":16:9) assert(ptr #3)
// +
// + bb4:
// +     %17 = load i8, #1, align 1
// +     %18 = icmp slt i8 %17, 0
// +     br %18 to bb5 else bb8
// +
// + bb5:
// +     %19 = load i8, #0, align 1
// +     %20 = icmp eq i8 %19, -1
// +     br %20 to bb6 else bb7
// +
// + bb6:
// +     %21 = load i8, #1, align 1
// +     %22 = and i8 %21, 1
// +     %23 = icmp ne i8 %22, 0
// +     br %23 to bb16(-1) else bb16(1)
// +
// + bb7:
// +     %24 = load i8, #0, align 1
// +     %25 = icmp eq i8 %24, 1
// +     br %25 to bb16(1) else bb16(0)
// +
// + bb8:
// +     %26 = load i8, #0, align 1
// +     store #2, i8 %26, align 1
// +     br bb9
// +
// + bb9:
// +     %27 = load i8, #1, align 1
// +     %28 = icmp ne i8 %27, 1
// +     br %28 to bb10 else bb15
// +
// + bb10:
// +     %29 = load i8, #2, align 1
// +     %30 = load i8, #0, align 1
// +     %31 = smul ov i8 %29, %30
// +     br %31:1 to bb11 else bb12
// +
// + bb11:
// +     abort at loc("__srcc_preamble.src":34:13) arithmetic(ptr #3)
// +
// + bb12:
// +     store #2, i8 %31:0, align 1
// +     %41 = load i8, #1, align 1
// +     %42 = ssub ov i8 %41, 1
// +     br %42:1 to bb13 else bb14
// +
// + bb13:
// +     abort at loc("__srcc_preamble.src":35:13) arithmetic(ptr #3)
// +
// + bb14:
// +     store #1, i8 %42:0, align 1
// +     br bb9
// +
// + bb15:
// +     %52 = load i8, #2, align 1
// +     br bb16(%52)
// +
// + bb16(i8 %53):
// +     ret i8 %53
// + }
// +
// + proc _S7exp_assFvx3ixix3I8xI8E.4 (
// +     i64 %0,
// +     i64 %1,
// +     i8 %2,
// +     i8 %3,
// + ) private ccc {
// +     #0 = 8, align 8
// +     #1 = 8, align 8
// +     #2 = 1, align 1
// +     #3 = 1, align 1
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     store #1, i64 %1, align 8
// +     store #2, i8 %2, align 1
// +     store #3, i8 %3, align 1
// +     %4 = load i64, #1, align 8
// +     %5 = call ccc ptr _S$3**=FRix2ixiE(ptr #0 dereferenceable 8, i64 %4)
// +     %6 = load i8, #3, align 1
// +     %7 = call ccc ptr _S$3**=FRI8x2I8xI8E(ptr #2 dereferenceable 1, i8 %6)
// +     ret
// + }
// +
// + proc _S$3**=FRix2ixiE (ptr %0 dereferenceable 8, i64 %1) inline private ccc -> ptr {
// +     #0 = 8, align 8
// +
// + entry:
// +     store #0, i64 %1, align 8
// +     %2 = load i64, %0, align 8
// +     %3 = load i64, #0, align 8
// +     %4 = call ccc i64 _S$2**Fixix3iE(i64 %2, i64 %3)
// +     store %0, i64 %4, align 8
// +     ret ptr %0
// + }
// +
// + proc _S$3**=FRI8x2I8xI8E (ptr %0 dereferenceable 1, i8 %1) inline private ccc -> ptr {
// +     #0 = 1, align 1
// +
// + entry:
// +     store #0, i8 %1, align 1
// +     %2 = load i8, %0, align 1
// +     %3 = load i8, #0, align 1
// +     %4 = call ccc i8 _S$2**FI8xI8x3I8E(i8 %2, i8 %3)
// +     store %0, i8 %4, align 1
// +     ret ptr %0
// + }
