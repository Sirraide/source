// R      %srcc --ir -fno-overflow-checks --target x86_64-unknown-linux %s
// R[//L] %srcc --llvm -fno-overflow-checks --target x86_64-unknown-linux %s
program test;

proc ints {
    proc f1 (i64, i64, i64, i64, i64, i64, i64, i64) extern native;
    proc f2 (i32, i32, i32, i32, i32, i32, i32, i32) extern native;
    proc f3 (i17, i17, i17, i17, i17, i17, i17, i17) extern native;
    proc f4 (i42, i42, i42, i42, i42, i42, i42, i42) extern native;
    proc f5 (i128, i128, i128, i128, i128) extern native;
    proc f6 (i112, i112, i112, i112, i112) extern native;
    proc f7 (i65, i65, i65, i65, i65) extern native;
    proc f8 (i256) extern native;

    f1(1, 2, 3, 4, 5, 6, 7, 8);
    f2(1, 2, 3, 4, 5, 6, 7, 8);
    f3(1, 2, 3, 4, 5, 6, 7, 8);
    f4(1, 2, 3, 4, 5, 6, 7, 8);
    f5(1, 2, 3, 4, 5);
    f6(1, 2, 3, 4, 5);
    f7(1, 2, 3, 4, 5);
    f8(1);
}

proc int_lvalues {
    proc f9(i64, i32, i17, i42, i128, i112, i65, i256, i1, bool) extern native;
    i64 j1 = 1;
    i32 j2 = 1;
    i17 j3 = 1;
    i42 j4 = 1;
    i128 j5 = 1;
    i112 j6 = 1;
    i65 j7 = 1;
    i256 j8 = 1;
    i1 j9 = 0;
    bool j10 = true;
    f9(j1, j2, j3, j4, j5, j6, j7, j8, j9, j10);
}

struct a { i32 x; }
struct b { i32 x; i32 y; }
struct c { i64 x; i64 y; }
struct d { i64 x; i32 y; }
struct e { i32 x; i64 y; }
struct f { i128 x; }

proc g1 (a, a, a, a, a, a, a, a) extern native;
proc g2 (b, b, b, b, b, b, b, b) extern native;
proc g3 (c, c, c, c) extern native;
proc g4 (b, c, c, c, c, b, b) extern native;
proc g5 (i256, a, a, a, a, a, a, a) extern native;
proc g6 (d, d, d, d) extern native;
proc g7 (e, e, e, e) extern native;
proc g8 (f, f, f, f) extern native;

proc struct_rvalues {
    g1(a(1), a(1), a(1), a(1), a(1), a(1), a(1), a(1));
    g2(b(1, 2), b(1, 2), b(1, 2), b(1, 2), b(1, 2), b(1, 2), b(1, 2), b(1, 2));
    g3(c(1, 2), c(1, 2), c(1, 2), c(1, 2));
    g4(b(1, 2), c(1, 2), c(1, 2), c(1, 2), c(1, 2), b(1, 2), b(1, 2));
    g5(1, a(1), a(1), a(1), a(1), a(1), a(1), a(1));
    g6(d(1, 2), d(1, 2), d(1, 2), d(1, 2));
    g7(e(1, 2), e(1, 2), e(1, 2), e(1, 2));
    g8(f(1), f(2), f(3), f(4));
}

proc struct_lvalues {
    a a1 = 1;
    b b1 = b(1, 2);
    c c1 = c(1, 2);
    d d1 = d(1, 2);
    e e1 = e(1, 2);
    f f1 = f(1);
    g1(a1, a1, a1, a1, a1, a1, a1, a1);
    g2(b1, b1, b1, b1, b1, b1, b1, b1);
    g3(c1, c1, c1, c1);
    g4(b1, c1, c1, c1, c1, b1, b1);
    g5(1, a1, a1, a1, a1, a1, a1, a1);
    g6(d1, d1, d1, d1);
    g7(e1, e1, e1, e1);
    g8(f1, f1, f1, f1);
}

proc h1(inout a, inout a, inout a, inout a, inout a, a, a, inout a) extern nomangle;
proc h2(out a, out a, out a, out a, out a, a, a, out a) extern nomangle;

proc in_out {
    a a1 = 1;
    h1(a1, a1, a1, a1, a1, a1, a1, a1);
    h2(a1, a1, a1, a1, a1, a1, a1, a1);
}

proc h3(in a, in a, in a, in a, in a, in a, a, in a) extern nomangle;
proc h4(a, a, a, a, a, a, a, a) extern nomangle;
proc in_move_small {
    a a1 = 1;
    h3(a1, a1, a1, a1, a1, a1, a1, a1);
    h4(a1, a1, a1, a1, a1, a1, a1, a1);
}

struct big { i64[50] x; }
proc big1(in big, in big, in big, in big, in big, in big, big, in big, a) extern nomangle;
proc big2(big, big, big, big, big, big, big, big, a) extern nomangle;
proc big3(copy big, copy big, copy big, copy big, copy big, copy big, copy big, big, a) extern nomangle;
proc big4(inout big, inout big, inout big, inout big, inout big, inout big, big, inout big, a) extern nomangle;
proc big5(out big, out big, out big, out big, out big, out big, big, out big, a) extern nomangle;
proc big_struct {
    big b;
    big1(b, b, b, b, b, b, b, b, 42);
    big2(b, b, b, b, b, b, b, b, 42);
    big3(b, b, b, b, b, b, b, b, 42);
    big4(b, b, b, b, b, b, b, b, 42);
    big5(b, b, b, b, b, b, b, b, 42);
}

struct small { i16 a; i16 b; }
struct tiny { i8 a; i8 b; }
struct bits { i1 a; bool b; }

proc r1 extern native -> bool;
proc r2 extern native -> i1;
proc r3 extern native -> i4;
proc r4 extern native -> i7;
proc r5 extern native -> i8;
proc r6 extern native -> i16;
proc r7 extern native -> i17;
proc r8 extern native -> i32;
proc r9 extern native -> i42;
proc r10 extern native -> i64;
proc r11 extern native -> i65;
proc r12 extern native -> i111;
proc r13 extern native -> i128;
proc r14 extern native -> i129;
proc r15 extern native -> a;
proc r16 extern native -> b;
proc r17 extern native -> c;
proc r18 extern native -> big;
proc r19 extern native -> small;
proc r20 extern native -> tiny;
proc r21 extern native -> bits;
proc returns {
    var x1 = r1();
    var x2 = r2();
    var x3 = r3();
    var x4 = r4();
    var x5 = r5();
    var x6 = r6();
    var x7 = r7();
    var x8 = r8();
    var x9 = r9();
    var x10 = r10();
    var x11 = r11();
    var x12 = r12();
    var x13 = r13();
    var x14 = r14();
    var x15 = r15();
    var x16 = r16();
    var x17 = r17();
    var x18 = r18();
    var x19 = r19();
    var x20 = r20();
    var x21 = r21();
}

proc s1(i8[], i8[], i8[], i8[]) extern nomangle;
proc s2(inout i8[], copy i8[], out i8[], in i8[]) extern nomangle;
proc s3(inout i8[], copy i8[], out i8[], in i8[], in i8[], in i8[]) extern nomangle;
proc s4() extern nomangle -> i8[];
proc slices {
    var s = "q";
    s1("1", "2", "3", "4");
    s1(s, s, s, s);
    s2(s, s, s, s);
    s3(s, s, s, s, s, s);
    var q = s4();
}

proc cx extern nomangle;
proc c1(proc, proc, proc, proc) extern nomangle;
proc c2(inout proc, copy proc, out proc, in proc) extern nomangle;
proc c3(inout proc, copy proc, out proc, in proc, in proc, in proc) extern nomangle;
proc c4() extern nomangle -> proc;
proc closures {
    var c = cx;
    c1(cx, cx, cx, cx);
    c1(c, c, c, c);
    c2(c, c, c, c);
    c3(c, c, c, c, c, c);
    var q = c4();
}

// * @0 = "4\00"
// + @1 = "3\00"
// + @2 = "2\00"
// + @3 = "1\00"
// + @4 = "q\00"
// +
// + proc __src_main external fastcc {
// + entry:
// +     ret
// + }
// +
// + proc _S4intsFvE private fastcc {
// +     #0 = 16, align 16
// +     #1 = 16, align 16
// +     #2 = 16, align 16
// +     #3 = 16, align 16
// +     #4 = 16, align 16
// +     #5 = 16, align 8
// +     #6 = 16, align 8
// +     #7 = 16, align 8
// +     #8 = 16, align 8
// +     #9 = 16, align 8
// +     #10 = 16, align 8
// +     #11 = 16, align 8
// +     #12 = 16, align 8
// +     #13 = 16, align 8
// +     #14 = 16, align 8
// +     #15 = 32, align 8
// +
// + entry:
// +     call ccc void f1(
// +         i64 1,
// +         i64 2,
// +         i64 3,
// +         i64 4,
// +         i64 5,
// +         i64 6,
// +         i64 7,
// +         i64 8)
// +     call ccc void f2(
// +         i32 1,
// +         i32 2,
// +         i32 3,
// +         i32 4,
// +         i32 5,
// +         i32 6,
// +         i32 7,
// +         i32 8)
// +     call ccc void f3(
// +         i17 1 signext,
// +         i17 2 signext,
// +         i17 3 signext,
// +         i17 4 signext,
// +         i17 5 signext,
// +         i17 6 signext,
// +         i17 7 signext,
// +         i17 8 signext)
// +     call ccc void f4(
// +         i42 1 signext,
// +         i42 2 signext,
// +         i42 3 signext,
// +         i42 4 signext,
// +         i42 5 signext,
// +         i42 6 signext,
// +         i42 7 signext,
// +         i42 8 signext)
// +     store #0, i128 1, align 16
// +     %0 = load i128, #0, align 16
// +     store #1, i128 2, align 16
// +     %1 = load i128, #1, align 16
// +     store #2, i128 3, align 16
// +     %2 = load i128, #2, align 16
// +     store #3, i128 4, align 16
// +     %3 = load i128, #3, align 16
// +     store #4, i128 5, align 16
// +     %4 = load i128, #4, align 16
// +     call ccc void f5(
// +         i128 %0,
// +         i128 %1,
// +         i128 %2,
// +         i128 %3,
// +         i128 %4)
// +     store #5, i128 1, align 8
// +     %5 = load i64, #5, align 8
// +     %6 = ptradd #5, 8
// +     %7 = load i64, %6, align 8
// +     store #6, i128 2, align 8
// +     %8 = load i64, #6, align 8
// +     %9 = ptradd #6, 8
// +     %10 = load i64, %9, align 8
// +     store #7, i128 3, align 8
// +     %11 = load i64, #7, align 8
// +     %12 = ptradd #7, 8
// +     %13 = load i64, %12, align 8
// +     store #8, i128 4, align 8
// +     store #9, i128 5, align 8
// +     call ccc void f6(
// +         i64 %5,
// +         i64 %7,
// +         i64 %8,
// +         i64 %10,
// +         i64 %11,
// +         i64 %13,
// +         ptr #8 byval i128,
// +         ptr #9 byval i128)
// +     store #10, i128 1, align 8
// +     %14 = load i64, #10, align 8
// +     %15 = ptradd #10, 8
// +     %16 = load i64, %15, align 8
// +     store #11, i128 2, align 8
// +     %17 = load i64, #11, align 8
// +     %18 = ptradd #11, 8
// +     %19 = load i64, %18, align 8
// +     store #12, i128 3, align 8
// +     %20 = load i64, #12, align 8
// +     %21 = ptradd #12, 8
// +     %22 = load i64, %21, align 8
// +     store #13, i128 4, align 8
// +     store #14, i128 5, align 8
// +     call ccc void f7(
// +         i64 %14,
// +         i64 %16,
// +         i64 %17,
// +         i64 %19,
// +         i64 %20,
// +         i64 %22,
// +         ptr #13 byval i128,
// +         ptr #14 byval i128)
// +     store #15, i256 1, align 8
// +     call ccc void f8(ptr #15 byval i8[32])
// +     ret
// + }
// +
// + proc f1 (
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// + ) external ccc;
// +
// + proc f2 (
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// + ) external ccc;
// +
// + proc f3 (
// +     i17 signext,
// +     i17 signext,
// +     i17 signext,
// +     i17 signext,
// +     i17 signext,
// +     i17 signext,
// +     i17 signext,
// +     i17 signext,
// + ) external ccc;
// +
// + proc f4 (
// +     i42 signext,
// +     i42 signext,
// +     i42 signext,
// +     i42 signext,
// +     i42 signext,
// +     i42 signext,
// +     i42 signext,
// +     i42 signext,
// + ) external ccc;
// +
// + proc f5 (
// +     i128,
// +     i128,
// +     i128,
// +     i128,
// +     i128,
// + ) external ccc;
// +
// + proc f6 (
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     ptr byval i128,
// +     ptr byval i128,
// + ) external ccc;
// +
// + proc f7 (
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     ptr byval i128,
// +     ptr byval i128,
// + ) external ccc;
// +
// + proc f8 (ptr byval i8[32]) external ccc;
// +
// + proc _S11int_lvaluesFvE private fastcc {
// +     #0 = 8, align 8
// +     #1 = 4, align 4
// +     #2 = 4, align 4
// +     #3 = 8, align 8
// +     #4 = 16, align 16
// +     #5 = 16, align 8
// +     #6 = 16, align 8
// +     #7 = 32, align 8
// +     #8 = 1, align 1
// +     #9 = 1, align 1
// +     #10 = 16, align 16
// +     #11 = 16, align 8
// +     #12 = 16, align 8
// +     #13 = 32, align 8
// +
// + entry:
// +     store #0, i64 1, align 8
// +     store #1, i32 1, align 4
// +     store #2, i32 1, align 4
// +     store #3, i64 1, align 8
// +     store #4, i128 1, align 16
// +     store #5, i128 1, align 8
// +     store #6, i128 1, align 8
// +     store #7, i256 1, align 8
// +     store #8, i8 0, align 1
// +     store #9, i8 -1, align 1
// +     %0 = load i64, #0, align 8
// +     %1 = load i32, #1, align 4
// +     %2 = load i32, #2, align 4
// +     %3 = trunc i32 %2 to i17
// +     %4 = load i64, #3, align 8
// +     %5 = trunc i64 %4 to i42
// +     %6 = load i128, #4, align 16
// +     store #10, i128 %6, align 16
// +     %7 = load i128, #10, align 16
// +     %8 = load i128, #5, align 8
// +     %9 = trunc i128 %8 to i112
// +     %10 = sext i112 %9 to i128
// +     store #11, i128 %10, align 8
// +     %11 = load i128, #6, align 8
// +     %12 = trunc i128 %11 to i65
// +     %13 = sext i65 %12 to i128
// +     store #12, i128 %13, align 8
// +     %14 = load i256, #7, align 8
// +     store #13, i256 %14, align 8
// +     %15 = load i8, #8, align 1
// +     %16 = trunc i8 %15 to i1
// +     %17 = load i8, #9, align 1
// +     %18 = trunc i8 %17 to i1
// +     call ccc void f9(
// +         i64 %0,
// +         i32 %1,
// +         i17 %3 signext,
// +         i42 %5 signext,
// +         i128 %7,
// +         ptr #11 byval i128,
// +         ptr #12 byval i128,
// +         ptr #13 byval i8[32],
// +         i1 %16 signext,
// +         i1 %18 zeroext)
// +     ret
// + }
// +
// + proc f9 (
// +     i64,
// +     i32,
// +     i17 signext,
// +     i42 signext,
// +     i128,
// +     ptr byval i128,
// +     ptr byval i128,
// +     ptr byval i8[32],
// +     i1 signext,
// +     i1 zeroext,
// + ) external ccc;
// +
// + proc _S14struct_rvaluesFvE private fastcc {
// +     #0 = 4, align 4
// +     #1 = 4, align 4
// +     #2 = 4, align 4
// +     #3 = 4, align 4
// +     #4 = 4, align 4
// +     #5 = 4, align 4
// +     #6 = 4, align 4
// +     #7 = 4, align 4
// +     #8 = 8, align 4
// +     #9 = 8, align 4
// +     #10 = 8, align 4
// +     #11 = 8, align 4
// +     #12 = 8, align 4
// +     #13 = 8, align 4
// +     #14 = 8, align 4
// +     #15 = 8, align 4
// +     #16 = 16, align 8
// +     #17 = 16, align 8
// +     #18 = 16, align 8
// +     #19 = 16, align 8
// +     #20 = 8, align 4
// +     #21 = 16, align 8
// +     #22 = 16, align 8
// +     #23 = 16, align 8
// +     #24 = 16, align 8
// +     #25 = 8, align 4
// +     #26 = 8, align 4
// +     #27 = 32, align 8
// +     #28 = 4, align 4
// +     #29 = 4, align 4
// +     #30 = 4, align 4
// +     #31 = 4, align 4
// +     #32 = 4, align 4
// +     #33 = 4, align 4
// +     #34 = 4, align 4
// +     #35 = 12, align 8
// +     #36 = 12, align 8
// +     #37 = 12, align 8
// +     #38 = 12, align 8
// +     #39 = 16, align 8
// +     #40 = 16, align 8
// +     #41 = 16, align 8
// +     #42 = 16, align 8
// +     #43 = 16, align 16
// +     #44 = 16, align 16
// +     #45 = 16, align 16
// +     #46 = 16, align 16
// +
// + entry:
// +     store #0, i32 1, align 4
// +     %0 = load i32, #0, align 4
// +     store #1, i32 1, align 4
// +     %1 = load i32, #1, align 4
// +     store #2, i32 1, align 4
// +     %2 = load i32, #2, align 4
// +     store #3, i32 1, align 4
// +     %3 = load i32, #3, align 4
// +     store #4, i32 1, align 4
// +     %4 = load i32, #4, align 4
// +     store #5, i32 1, align 4
// +     %5 = load i32, #5, align 4
// +     store #6, i32 1, align 4
// +     %6 = load i32, #6, align 4
// +     store #7, i32 1, align 4
// +     %7 = load i32, #7, align 4
// +     call ccc void g1(
// +         i32 %0,
// +         i32 %1,
// +         i32 %2,
// +         i32 %3,
// +         i32 %4,
// +         i32 %5,
// +         i32 %6,
// +         i32 %7)
// +     store #8, i32 1, align 4
// +     %8 = ptradd #8, 4
// +     store %8, i32 2, align 4
// +     %9 = load i64, #8, align 8
// +     store #9, i32 1, align 4
// +     %10 = ptradd #9, 4
// +     store %10, i32 2, align 4
// +     %11 = load i64, #9, align 8
// +     store #10, i32 1, align 4
// +     %12 = ptradd #10, 4
// +     store %12, i32 2, align 4
// +     %13 = load i64, #10, align 8
// +     store #11, i32 1, align 4
// +     %14 = ptradd #11, 4
// +     store %14, i32 2, align 4
// +     %15 = load i64, #11, align 8
// +     store #12, i32 1, align 4
// +     %16 = ptradd #12, 4
// +     store %16, i32 2, align 4
// +     %17 = load i64, #12, align 8
// +     store #13, i32 1, align 4
// +     %18 = ptradd #13, 4
// +     store %18, i32 2, align 4
// +     %19 = load i64, #13, align 8
// +     store #14, i32 1, align 4
// +     %20 = ptradd #14, 4
// +     store %20, i32 2, align 4
// +     %21 = load i64, #14, align 8
// +     store #15, i32 1, align 4
// +     %22 = ptradd #15, 4
// +     store %22, i32 2, align 4
// +     %23 = load i64, #15, align 8
// +     call ccc void g2(
// +         i64 %9,
// +         i64 %11,
// +         i64 %13,
// +         i64 %15,
// +         i64 %17,
// +         i64 %19,
// +         i64 %21,
// +         i64 %23)
// +     store #16, i64 1, align 8
// +     %24 = ptradd #16, 8
// +     store %24, i64 2, align 8
// +     %25 = load i64, #16, align 8
// +     %26 = ptradd #16, 8
// +     %27 = load i64, %26, align 8
// +     store #17, i64 1, align 8
// +     %28 = ptradd #17, 8
// +     store %28, i64 2, align 8
// +     %29 = load i64, #17, align 8
// +     %30 = ptradd #17, 8
// +     %31 = load i64, %30, align 8
// +     store #18, i64 1, align 8
// +     %32 = ptradd #18, 8
// +     store %32, i64 2, align 8
// +     %33 = load i64, #18, align 8
// +     %34 = ptradd #18, 8
// +     %35 = load i64, %34, align 8
// +     store #19, i64 1, align 8
// +     %36 = ptradd #19, 8
// +     store %36, i64 2, align 8
// +     call ccc void g3(
// +         i64 %25,
// +         i64 %27,
// +         i64 %29,
// +         i64 %31,
// +         i64 %33,
// +         i64 %35,
// +         ptr #19 byval i8[16])
// +     store #20, i32 1, align 4
// +     %37 = ptradd #20, 4
// +     store %37, i32 2, align 4
// +     %38 = load i64, #20, align 8
// +     store #21, i64 1, align 8
// +     %39 = ptradd #21, 8
// +     store %39, i64 2, align 8
// +     %40 = load i64, #21, align 8
// +     %41 = ptradd #21, 8
// +     %42 = load i64, %41, align 8
// +     store #22, i64 1, align 8
// +     %43 = ptradd #22, 8
// +     store %43, i64 2, align 8
// +     %44 = load i64, #22, align 8
// +     %45 = ptradd #22, 8
// +     %46 = load i64, %45, align 8
// +     store #23, i64 1, align 8
// +     %47 = ptradd #23, 8
// +     store %47, i64 2, align 8
// +     store #24, i64 1, align 8
// +     %48 = ptradd #24, 8
// +     store %48, i64 2, align 8
// +     store #25, i32 1, align 4
// +     %49 = ptradd #25, 4
// +     store %49, i32 2, align 4
// +     %50 = load i64, #25, align 8
// +     store #26, i32 1, align 4
// +     %51 = ptradd #26, 4
// +     store %51, i32 2, align 4
// +     %52 = load i64, #26, align 8
// +     call ccc void g4(
// +         i64 %38,
// +         i64 %40,
// +         i64 %42,
// +         i64 %44,
// +         i64 %46,
// +         ptr #23 byval i8[16],
// +         ptr #24 byval i8[16],
// +         i64 %50,
// +         i64 %52)
// +     store #27, i256 1, align 8
// +     store #28, i32 1, align 4
// +     %53 = load i32, #28, align 4
// +     store #29, i32 1, align 4
// +     %54 = load i32, #29, align 4
// +     store #30, i32 1, align 4
// +     %55 = load i32, #30, align 4
// +     store #31, i32 1, align 4
// +     %56 = load i32, #31, align 4
// +     store #32, i32 1, align 4
// +     %57 = load i32, #32, align 4
// +     store #33, i32 1, align 4
// +     %58 = load i32, #33, align 4
// +     store #34, i32 1, align 4
// +     %59 = load i32, #34, align 4
// +     call ccc void g5(
// +         ptr #27 byval i8[32],
// +         i32 %53,
// +         i32 %54,
// +         i32 %55,
// +         i32 %56,
// +         i32 %57,
// +         i32 %58,
// +         i32 %59)
// +     store #35, i64 1, align 8
// +     %60 = ptradd #35, 8
// +     store %60, i32 2, align 4
// +     %61 = load i64, #35, align 8
// +     %62 = ptradd #35, 8
// +     %63 = load i32, %62, align 4
// +     store #36, i64 1, align 8
// +     %64 = ptradd #36, 8
// +     store %64, i32 2, align 4
// +     %65 = load i64, #36, align 8
// +     %66 = ptradd #36, 8
// +     %67 = load i32, %66, align 4
// +     store #37, i64 1, align 8
// +     %68 = ptradd #37, 8
// +     store %68, i32 2, align 4
// +     %69 = load i64, #37, align 8
// +     %70 = ptradd #37, 8
// +     %71 = load i32, %70, align 4
// +     store #38, i64 1, align 8
// +     %72 = ptradd #38, 8
// +     store %72, i32 2, align 4
// +     call ccc void g6(
// +         i64 %61,
// +         i32 %63,
// +         i64 %65,
// +         i32 %67,
// +         i64 %69,
// +         i32 %71,
// +         ptr #38 byval i8[12])
// +     store #39, i32 1, align 4
// +     %73 = ptradd #39, 8
// +     store %73, i64 2, align 8
// +     %74 = load i64, #39, align 8
// +     %75 = ptradd #39, 8
// +     %76 = load i64, %75, align 8
// +     store #40, i32 1, align 4
// +     %77 = ptradd #40, 8
// +     store %77, i64 2, align 8
// +     %78 = load i64, #40, align 8
// +     %79 = ptradd #40, 8
// +     %80 = load i64, %79, align 8
// +     store #41, i32 1, align 4
// +     %81 = ptradd #41, 8
// +     store %81, i64 2, align 8
// +     %82 = load i64, #41, align 8
// +     %83 = ptradd #41, 8
// +     %84 = load i64, %83, align 8
// +     store #42, i32 1, align 4
// +     %85 = ptradd #42, 8
// +     store %85, i64 2, align 8
// +     call ccc void g7(
// +         i64 %74,
// +         i64 %76,
// +         i64 %78,
// +         i64 %80,
// +         i64 %82,
// +         i64 %84,
// +         ptr #42 byval i8[16])
// +     store #43, i128 1, align 16
// +     %86 = load i64, #43, align 8
// +     %87 = ptradd #43, 8
// +     %88 = load i64, %87, align 8
// +     store #44, i128 2, align 16
// +     %89 = load i64, #44, align 8
// +     %90 = ptradd #44, 8
// +     %91 = load i64, %90, align 8
// +     store #45, i128 3, align 16
// +     %92 = load i64, #45, align 8
// +     %93 = ptradd #45, 8
// +     %94 = load i64, %93, align 8
// +     store #46, i128 4, align 16
// +     call ccc void g8(
// +         i64 %86,
// +         i64 %88,
// +         i64 %89,
// +         i64 %91,
// +         i64 %92,
// +         i64 %94,
// +         ptr #46 byval i8[16])
// +     ret
// + }
// +
// + proc g1 (
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// + ) external ccc;
// +
// + proc g2 (
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// + ) external ccc;
// +
// + proc g3 (
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     ptr byval i8[16],
// + ) external ccc;
// +
// + proc g4 (
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     ptr byval i8[16],
// +     ptr byval i8[16],
// +     i64,
// +     i64,
// + ) external ccc;
// +
// + proc g5 (
// +     ptr byval i8[32],
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// + ) external ccc;
// +
// + proc g6 (
// +     i64,
// +     i32,
// +     i64,
// +     i32,
// +     i64,
// +     i32,
// +     ptr byval i8[12],
// + ) external ccc;
// +
// + proc g7 (
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     ptr byval i8[16],
// + ) external ccc;
// +
// + proc g8 (
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     i64,
// +     ptr byval i8[16],
// + ) external ccc;
// +
// + proc _S14struct_lvaluesFvE private fastcc {
// +     #0 = 4, align 4
// +     #1 = 8, align 4
// +     #2 = 16, align 8
// +     #3 = 12, align 8
// +     #4 = 16, align 8
// +     #5 = 16, align 16
// +     #6 = 4, align 4
// +     #7 = 4, align 4
// +     #8 = 4, align 4
// +     #9 = 4, align 4
// +     #10 = 4, align 4
// +     #11 = 4, align 4
// +     #12 = 4, align 4
// +     #13 = 4, align 4
// +     #14 = 8, align 4
// +     #15 = 8, align 4
// +     #16 = 8, align 4
// +     #17 = 8, align 4
// +     #18 = 8, align 4
// +     #19 = 8, align 4
// +     #20 = 8, align 4
// +     #21 = 8, align 4
// +     #22 = 16, align 8
// +     #23 = 16, align 8
// +     #24 = 16, align 8
// +     #25 = 16, align 8
// +     #26 = 8, align 4
// +     #27 = 16, align 8
// +     #28 = 16, align 8
// +     #29 = 16, align 8
// +     #30 = 16, align 8
// +     #31 = 8, align 4
// +     #32 = 8, align 4
// +     #33 = 32, align 8
// +     #34 = 4, align 4
// +     #35 = 4, align 4
// +     #36 = 4, align 4
// +     #37 = 4, align 4
// +     #38 = 4, align 4
// +     #39 = 4, align 4
// +     #40 = 4, align 4
// +     #41 = 12, align 8
// +     #42 = 12, align 8
// +     #43 = 12, align 8
// +     #44 = 12, align 8
// +     #45 = 16, align 8
// +     #46 = 16, align 8
// +     #47 = 16, align 8
// +     #48 = 16, align 8
// +     #49 = 16, align 16
// +     #50 = 16, align 16
// +     #51 = 16, align 16
// +     #52 = 16, align 16
// +
// + entry:
// +     store #0, i32 1, align 4
// +     store #1, i32 1, align 4
// +     %0 = ptradd #1, 4
// +     store %0, i32 2, align 4
// +     store #2, i64 1, align 8
// +     %1 = ptradd #2, 8
// +     store %1, i64 2, align 8
// +     store #3, i64 1, align 8
// +     %2 = ptradd #3, 8
// +     store %2, i32 2, align 4
// +     store #4, i32 1, align 4
// +     %3 = ptradd #4, 8
// +     store %3, i64 2, align 8
// +     store #5, i128 1, align 16
// +     copy #6 <- #0, 4
// +     %4 = load i32, #6, align 4
// +     copy #7 <- #0, 4
// +     %5 = load i32, #7, align 4
// +     copy #8 <- #0, 4
// +     %6 = load i32, #8, align 4
// +     copy #9 <- #0, 4
// +     %7 = load i32, #9, align 4
// +     copy #10 <- #0, 4
// +     %8 = load i32, #10, align 4
// +     copy #11 <- #0, 4
// +     %9 = load i32, #11, align 4
// +     copy #12 <- #0, 4
// +     %10 = load i32, #12, align 4
// +     copy #13 <- #0, 4
// +     %11 = load i32, #13, align 4
// +     call ccc void g1(
// +         i32 %4,
// +         i32 %5,
// +         i32 %6,
// +         i32 %7,
// +         i32 %8,
// +         i32 %9,
// +         i32 %10,
// +         i32 %11)
// +     copy #14 <- #1, 8
// +     %12 = load i64, #14, align 8
// +     copy #15 <- #1, 8
// +     %13 = load i64, #15, align 8
// +     copy #16 <- #1, 8
// +     %14 = load i64, #16, align 8
// +     copy #17 <- #1, 8
// +     %15 = load i64, #17, align 8
// +     copy #18 <- #1, 8
// +     %16 = load i64, #18, align 8
// +     copy #19 <- #1, 8
// +     %17 = load i64, #19, align 8
// +     copy #20 <- #1, 8
// +     %18 = load i64, #20, align 8
// +     copy #21 <- #1, 8
// +     %19 = load i64, #21, align 8
// +     call ccc void g2(
// +         i64 %12,
// +         i64 %13,
// +         i64 %14,
// +         i64 %15,
// +         i64 %16,
// +         i64 %17,
// +         i64 %18,
// +         i64 %19)
// +     copy #22 <- #2, 16
// +     %20 = load i64, #22, align 8
// +     %21 = ptradd #22, 8
// +     %22 = load i64, %21, align 8
// +     copy #23 <- #2, 16
// +     %23 = load i64, #23, align 8
// +     %24 = ptradd #23, 8
// +     %25 = load i64, %24, align 8
// +     copy #24 <- #2, 16
// +     %26 = load i64, #24, align 8
// +     %27 = ptradd #24, 8
// +     %28 = load i64, %27, align 8
// +     copy #25 <- #2, 16
// +     call ccc void g3(
// +         i64 %20,
// +         i64 %22,
// +         i64 %23,
// +         i64 %25,
// +         i64 %26,
// +         i64 %28,
// +         ptr #25 byval i8[16])
// +     copy #26 <- #1, 8
// +     %29 = load i64, #26, align 8
// +     copy #27 <- #2, 16
// +     %30 = load i64, #27, align 8
// +     %31 = ptradd #27, 8
// +     %32 = load i64, %31, align 8
// +     copy #28 <- #2, 16
// +     %33 = load i64, #28, align 8
// +     %34 = ptradd #28, 8
// +     %35 = load i64, %34, align 8
// +     copy #29 <- #2, 16
// +     copy #30 <- #2, 16
// +     copy #31 <- #1, 8
// +     %36 = load i64, #31, align 8
// +     copy #32 <- #1, 8
// +     %37 = load i64, #32, align 8
// +     call ccc void g4(
// +         i64 %29,
// +         i64 %30,
// +         i64 %32,
// +         i64 %33,
// +         i64 %35,
// +         ptr #29 byval i8[16],
// +         ptr #30 byval i8[16],
// +         i64 %36,
// +         i64 %37)
// +     store #33, i256 1, align 8
// +     copy #34 <- #0, 4
// +     %38 = load i32, #34, align 4
// +     copy #35 <- #0, 4
// +     %39 = load i32, #35, align 4
// +     copy #36 <- #0, 4
// +     %40 = load i32, #36, align 4
// +     copy #37 <- #0, 4
// +     %41 = load i32, #37, align 4
// +     copy #38 <- #0, 4
// +     %42 = load i32, #38, align 4
// +     copy #39 <- #0, 4
// +     %43 = load i32, #39, align 4
// +     copy #40 <- #0, 4
// +     %44 = load i32, #40, align 4
// +     call ccc void g5(
// +         ptr #33 byval i8[32],
// +         i32 %38,
// +         i32 %39,
// +         i32 %40,
// +         i32 %41,
// +         i32 %42,
// +         i32 %43,
// +         i32 %44)
// +     copy #41 <- #3, 12
// +     %45 = load i64, #41, align 8
// +     %46 = ptradd #41, 8
// +     %47 = load i32, %46, align 4
// +     copy #42 <- #3, 12
// +     %48 = load i64, #42, align 8
// +     %49 = ptradd #42, 8
// +     %50 = load i32, %49, align 4
// +     copy #43 <- #3, 12
// +     %51 = load i64, #43, align 8
// +     %52 = ptradd #43, 8
// +     %53 = load i32, %52, align 4
// +     copy #44 <- #3, 12
// +     call ccc void g6(
// +         i64 %45,
// +         i32 %47,
// +         i64 %48,
// +         i32 %50,
// +         i64 %51,
// +         i32 %53,
// +         ptr #44 byval i8[12])
// +     copy #45 <- #4, 16
// +     %54 = load i64, #45, align 8
// +     %55 = ptradd #45, 8
// +     %56 = load i64, %55, align 8
// +     copy #46 <- #4, 16
// +     %57 = load i64, #46, align 8
// +     %58 = ptradd #46, 8
// +     %59 = load i64, %58, align 8
// +     copy #47 <- #4, 16
// +     %60 = load i64, #47, align 8
// +     %61 = ptradd #47, 8
// +     %62 = load i64, %61, align 8
// +     copy #48 <- #4, 16
// +     call ccc void g7(
// +         i64 %54,
// +         i64 %56,
// +         i64 %57,
// +         i64 %59,
// +         i64 %60,
// +         i64 %62,
// +         ptr #48 byval i8[16])
// +     copy #49 <- #5, 16
// +     %63 = load i64, #49, align 8
// +     %64 = ptradd #49, 8
// +     %65 = load i64, %64, align 8
// +     copy #50 <- #5, 16
// +     %66 = load i64, #50, align 8
// +     %67 = ptradd #50, 8
// +     %68 = load i64, %67, align 8
// +     copy #51 <- #5, 16
// +     %69 = load i64, #51, align 8
// +     %70 = ptradd #51, 8
// +     %71 = load i64, %70, align 8
// +     copy #52 <- #5, 16
// +     call ccc void g8(
// +         i64 %63,
// +         i64 %65,
// +         i64 %66,
// +         i64 %68,
// +         i64 %69,
// +         i64 %71,
// +         ptr #52 byval i8[16])
// +     ret
// + }
// +
// + proc _S6in_outFvE private fastcc {
// +     #0 = 4, align 4
// +     #1 = 4, align 4
// +     #2 = 4, align 4
// +     #3 = 4, align 4
// +     #4 = 4, align 4
// +
// + entry:
// +     store #0, i32 1, align 4
// +     copy #1 <- #0, 4
// +     %0 = load i32, #1, align 4
// +     copy #2 <- #0, 4
// +     %1 = load i32, #2, align 4
// +     call fastcc void h1(
// +         ptr #0 dereferenceable 4,
// +         ptr #0 dereferenceable 4,
// +         ptr #0 dereferenceable 4,
// +         ptr #0 dereferenceable 4,
// +         ptr #0 dereferenceable 4,
// +         i32 %0,
// +         i32 %1,
// +         ptr #0 dereferenceable 4)
// +     copy #3 <- #0, 4
// +     %2 = load i32, #3, align 4
// +     copy #4 <- #0, 4
// +     %3 = load i32, #4, align 4
// +     call fastcc void h2(
// +         ptr #0 dereferenceable 4,
// +         ptr #0 dereferenceable 4,
// +         ptr #0 dereferenceable 4,
// +         ptr #0 dereferenceable 4,
// +         ptr #0 dereferenceable 4,
// +         i32 %2,
// +         i32 %3,
// +         ptr #0 dereferenceable 4)
// +     ret
// + }
// +
// + proc h1 (
// +     ptr dereferenceable 4,
// +     ptr dereferenceable 4,
// +     ptr dereferenceable 4,
// +     ptr dereferenceable 4,
// +     ptr dereferenceable 4,
// +     i32,
// +     i32,
// +     ptr dereferenceable 4,
// + ) external fastcc;
// +
// + proc h2 (
// +     ptr dereferenceable 4,
// +     ptr dereferenceable 4,
// +     ptr dereferenceable 4,
// +     ptr dereferenceable 4,
// +     ptr dereferenceable 4,
// +     i32,
// +     i32,
// +     ptr dereferenceable 4,
// + ) external fastcc;
// +
// + proc _S13in_move_smallFvE private fastcc {
// +     #0 = 4, align 4
// +     #1 = 4, align 4
// +     #2 = 4, align 4
// +     #3 = 4, align 4
// +     #4 = 4, align 4
// +     #5 = 4, align 4
// +     #6 = 4, align 4
// +     #7 = 4, align 4
// +     #8 = 4, align 4
// +     #9 = 4, align 4
// +     #10 = 4, align 4
// +     #11 = 4, align 4
// +     #12 = 4, align 4
// +     #13 = 4, align 4
// +     #14 = 4, align 4
// +     #15 = 4, align 4
// +     #16 = 4, align 4
// +
// + entry:
// +     store #0, i32 1, align 4
// +     copy #1 <- #0, 4
// +     %0 = load i32, #1, align 4
// +     copy #2 <- #0, 4
// +     %1 = load i32, #2, align 4
// +     copy #3 <- #0, 4
// +     %2 = load i32, #3, align 4
// +     copy #4 <- #0, 4
// +     %3 = load i32, #4, align 4
// +     copy #5 <- #0, 4
// +     %4 = load i32, #5, align 4
// +     copy #6 <- #0, 4
// +     %5 = load i32, #6, align 4
// +     copy #7 <- #0, 4
// +     %6 = load i32, #7, align 4
// +     copy #8 <- #0, 4
// +     %7 = load i32, #8, align 4
// +     call fastcc void h3(
// +         i32 %0,
// +         i32 %1,
// +         i32 %2,
// +         i32 %3,
// +         i32 %4,
// +         i32 %5,
// +         i32 %6,
// +         i32 %7)
// +     copy #9 <- #0, 4
// +     %8 = load i32, #9, align 4
// +     copy #10 <- #0, 4
// +     %9 = load i32, #10, align 4
// +     copy #11 <- #0, 4
// +     %10 = load i32, #11, align 4
// +     copy #12 <- #0, 4
// +     %11 = load i32, #12, align 4
// +     copy #13 <- #0, 4
// +     %12 = load i32, #13, align 4
// +     copy #14 <- #0, 4
// +     %13 = load i32, #14, align 4
// +     copy #15 <- #0, 4
// +     %14 = load i32, #15, align 4
// +     copy #16 <- #0, 4
// +     %15 = load i32, #16, align 4
// +     call fastcc void h4(
// +         i32 %8,
// +         i32 %9,
// +         i32 %10,
// +         i32 %11,
// +         i32 %12,
// +         i32 %13,
// +         i32 %14,
// +         i32 %15)
// +     ret
// + }
// +
// + proc h3 (
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// + ) external fastcc;
// +
// + proc h4 (
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// +     i32,
// + ) external fastcc;
// +
// + proc _S10big_structFvE private fastcc {
// +     #0 = 400, align 8
// +     #1 = 400, align 8
// +     #2 = 400, align 8
// +     #3 = 400, align 8
// +     #4 = 400, align 8
// +     #5 = 400, align 8
// +     #6 = 400, align 8
// +     #7 = 400, align 8
// +     #8 = 400, align 8
// +     #9 = 4, align 4
// +     #10 = 400, align 8
// +     #11 = 400, align 8
// +     #12 = 400, align 8
// +     #13 = 400, align 8
// +     #14 = 400, align 8
// +     #15 = 400, align 8
// +     #16 = 400, align 8
// +     #17 = 400, align 8
// +     #18 = 4, align 4
// +     #19 = 400, align 8
// +     #20 = 400, align 8
// +     #21 = 400, align 8
// +     #22 = 400, align 8
// +     #23 = 400, align 8
// +     #24 = 400, align 8
// +     #25 = 400, align 8
// +     #26 = 400, align 8
// +     #27 = 4, align 4
// +     #28 = 400, align 8
// +     #29 = 4, align 4
// +     #30 = 400, align 8
// +     #31 = 4, align 4
// +
// + entry:
// +     set ptr #0, i8 0, i64 400
// +     copy #1 <- #0, 400
// +     copy #2 <- #0, 400
// +     copy #3 <- #0, 400
// +     copy #4 <- #0, 400
// +     copy #5 <- #0, 400
// +     copy #6 <- #0, 400
// +     copy #7 <- #0, 400
// +     copy #8 <- #0, 400
// +     store #9, i32 42, align 4
// +     %0 = load i32, #9, align 4
// +     call fastcc void big1(
// +         ptr #1 dereferenceable 400,
// +         ptr #2 dereferenceable 400,
// +         ptr #3 dereferenceable 400,
// +         ptr #4 dereferenceable 400,
// +         ptr #5 dereferenceable 400,
// +         ptr #6 dereferenceable 400,
// +         ptr #7 byval i8[400],
// +         ptr #8 dereferenceable 400,
// +         i32 %0)
// +     copy #10 <- #0, 400
// +     copy #11 <- #0, 400
// +     copy #12 <- #0, 400
// +     copy #13 <- #0, 400
// +     copy #14 <- #0, 400
// +     copy #15 <- #0, 400
// +     copy #16 <- #0, 400
// +     copy #17 <- #0, 400
// +     store #18, i32 42, align 4
// +     %1 = load i32, #18, align 4
// +     call fastcc void big2(
// +         ptr #10 byval i8[400],
// +         ptr #11 byval i8[400],
// +         ptr #12 byval i8[400],
// +         ptr #13 byval i8[400],
// +         ptr #14 byval i8[400],
// +         ptr #15 byval i8[400],
// +         ptr #16 byval i8[400],
// +         ptr #17 byval i8[400],
// +         i32 %1)
// +     copy #19 <- #0, 400
// +     copy #20 <- #0, 400
// +     copy #21 <- #0, 400
// +     copy #22 <- #0, 400
// +     copy #23 <- #0, 400
// +     copy #24 <- #0, 400
// +     copy #25 <- #0, 400
// +     copy #26 <- #0, 400
// +     store #27, i32 42, align 4
// +     %2 = load i32, #27, align 4
// +     call fastcc void big3(
// +         ptr #19 byval i8[400],
// +         ptr #20 byval i8[400],
// +         ptr #21 byval i8[400],
// +         ptr #22 byval i8[400],
// +         ptr #23 byval i8[400],
// +         ptr #24 byval i8[400],
// +         ptr #25 byval i8[400],
// +         ptr #26 byval i8[400],
// +         i32 %2)
// +     copy #28 <- #0, 400
// +     store #29, i32 42, align 4
// +     %3 = load i32, #29, align 4
// +     call fastcc void big4(
// +         ptr #0 dereferenceable 400,
// +         ptr #0 dereferenceable 400,
// +         ptr #0 dereferenceable 400,
// +         ptr #0 dereferenceable 400,
// +         ptr #0 dereferenceable 400,
// +         ptr #0 dereferenceable 400,
// +         ptr #28 byval i8[400],
// +         ptr #0 dereferenceable 400,
// +         i32 %3)
// +     copy #30 <- #0, 400
// +     store #31, i32 42, align 4
// +     %4 = load i32, #31, align 4
// +     call fastcc void big5(
// +         ptr #0 dereferenceable 400,
// +         ptr #0 dereferenceable 400,
// +         ptr #0 dereferenceable 400,
// +         ptr #0 dereferenceable 400,
// +         ptr #0 dereferenceable 400,
// +         ptr #0 dereferenceable 400,
// +         ptr #30 byval i8[400],
// +         ptr #0 dereferenceable 400,
// +         i32 %4)
// +     ret
// + }
// +
// + proc big1 (
// +     ptr dereferenceable 400,
// +     ptr dereferenceable 400,
// +     ptr dereferenceable 400,
// +     ptr dereferenceable 400,
// +     ptr dereferenceable 400,
// +     ptr dereferenceable 400,
// +     ptr byval i8[400],
// +     ptr dereferenceable 400,
// +     i32,
// + ) external fastcc;
// +
// + proc big2 (
// +     ptr byval i8[400],
// +     ptr byval i8[400],
// +     ptr byval i8[400],
// +     ptr byval i8[400],
// +     ptr byval i8[400],
// +     ptr byval i8[400],
// +     ptr byval i8[400],
// +     ptr byval i8[400],
// +     i32,
// + ) external fastcc;
// +
// + proc big3 (
// +     ptr byval i8[400],
// +     ptr byval i8[400],
// +     ptr byval i8[400],
// +     ptr byval i8[400],
// +     ptr byval i8[400],
// +     ptr byval i8[400],
// +     ptr byval i8[400],
// +     ptr byval i8[400],
// +     i32,
// + ) external fastcc;
// +
// + proc big4 (
// +     ptr dereferenceable 400,
// +     ptr dereferenceable 400,
// +     ptr dereferenceable 400,
// +     ptr dereferenceable 400,
// +     ptr dereferenceable 400,
// +     ptr dereferenceable 400,
// +     ptr byval i8[400],
// +     ptr dereferenceable 400,
// +     i32,
// + ) external fastcc;
// +
// + proc big5 (
// +     ptr dereferenceable 400,
// +     ptr dereferenceable 400,
// +     ptr dereferenceable 400,
// +     ptr dereferenceable 400,
// +     ptr dereferenceable 400,
// +     ptr dereferenceable 400,
// +     ptr byval i8[400],
// +     ptr dereferenceable 400,
// +     i32,
// + ) external fastcc;
// +
// + proc _S7returnsFvE private fastcc {
// +     #0 = 1, align 1
// +     #1 = 1, align 1
// +     #2 = 1, align 1
// +     #3 = 1, align 1
// +     #4 = 1, align 1
// +     #5 = 2, align 2
// +     #6 = 4, align 4
// +     #7 = 4, align 4
// +     #8 = 8, align 8
// +     #9 = 8, align 8
// +     #10 = 16, align 8
// +     #11 = 16, align 8
// +     #12 = 16, align 16
// +     #13 = 24, align 8
// +     #14 = 4, align 4
// +     #15 = 8, align 4
// +     #16 = 16, align 8
// +     #17 = 400, align 8
// +     #18 = 4, align 2
// +     #19 = 2, align 1
// +     #20 = 2, align 1
// +     #21 = 16, align 8
// +     #22 = 16, align 8
// +     #23 = 24, align 8
// +
// + entry:
// +     %0 = call ccc zeroext i1 r1()
// +     %1 = sext i1 %0 to i8
// +     store #0, i8 %1, align 1
// +     %2 = call ccc signext i1 r2()
// +     %3 = sext i1 %2 to i8
// +     store #1, i8 %3, align 1
// +     %4 = call ccc signext i4 r3()
// +     %5 = sext i4 %4 to i8
// +     store #2, i8 %5, align 1
// +     %6 = call ccc signext i7 r4()
// +     %7 = sext i7 %6 to i8
// +     store #3, i8 %7, align 1
// +     %8 = call ccc i8 r5()
// +     store #4, i8 %8, align 1
// +     %9 = call ccc i16 r6()
// +     store #5, i16 %9, align 2
// +     %10 = call ccc signext i17 r7()
// +     %11 = sext i17 %10 to i32
// +     store #6, i32 %11, align 4
// +     %12 = call ccc i32 r8()
// +     store #7, i32 %12, align 4
// +     %13 = call ccc signext i42 r9()
// +     %14 = sext i42 %13 to i64
// +     store #8, i64 %14, align 8
// +     %15 = call ccc i64 r10()
// +     store #9, i64 %15, align 8
// +     %16 = call ccc (i64, i64) r11()
// +     store #21, i64 %16:0, align 8
// +     %17 = ptradd #21, 8
// +     store %17, i64 %16:1, align 8
// +     %18 = load i128, #21, align 8
// +     %19 = trunc i128 %18 to i65
// +     %20 = sext i65 %19 to i128
// +     store #10, i128 %20, align 8
// +     %21 = call ccc (i64, i64) r12()
// +     store #22, i64 %21:0, align 8
// +     %22 = ptradd #22, 8
// +     store %22, i64 %21:1, align 8
// +     %23 = load i128, #22, align 8
// +     %24 = trunc i128 %23 to i111
// +     %25 = sext i111 %24 to i128
// +     store #11, i128 %25, align 8
// +     %26 = call ccc i128 r13()
// +     store #12, i128 %26, align 16
// +     call ccc void r14(ptr #23 sret i8[24])
// +     %27 = load i192, #23, align 8
// +     %28 = trunc i192 %27 to i129
// +     %29 = sext i129 %28 to i192
// +     store #13, i192 %29, align 8
// +     %30 = call ccc i32 r15()
// +     store #14, i32 %30, align 4
// +     %31 = call ccc i64 r16()
// +     store #15, i64 %31, align 8
// +     %32 = call ccc (i64, i64) r17()
// +     store #16, i64 %32:0, align 8
// +     %33 = ptradd #16, 8
// +     store %33, i64 %32:1, align 8
// +     call ccc void r18(ptr #17 sret i8[400])
// +     %34 = call ccc i32 r19()
// +     store #18, i32 %34, align 4
// +     %35 = call ccc i16 r20()
// +     store #19, i16 %35, align 2
// +     %36 = call ccc i16 r21()
// +     store #20, i16 %36, align 2
// +     ret
// + }
// +
// + proc r1 external ccc -> i1 zeroext;
// +
// + proc r2 external ccc -> i1 signext;
// +
// + proc r3 external ccc -> i4 signext;
// +
// + proc r4 external ccc -> i7 signext;
// +
// + proc r5 external ccc -> i8;
// +
// + proc r6 external ccc -> i16;
// +
// + proc r7 external ccc -> i17 signext;
// +
// + proc r8 external ccc -> i32;
// +
// + proc r9 external ccc -> i42 signext;
// +
// + proc r10 external ccc -> i64;
// +
// + proc r11 external ccc -> (i64, i64);
// +
// + proc r12 external ccc -> (i64, i64);
// +
// + proc r13 external ccc -> i128;
// +
// + proc r14 (ptr sret i8[24]) external ccc;
// +
// + proc r15 external ccc -> i32;
// +
// + proc r16 external ccc -> i64;
// +
// + proc r17 external ccc -> (i64, i64);
// +
// + proc r18 (ptr sret i8[400]) external ccc;
// +
// + proc r19 external ccc -> i32;
// +
// + proc r20 external ccc -> i16;
// +
// + proc r21 external ccc -> i16;
// +
// + proc _S6slicesFvE private fastcc {
// +     #0 = 16, align 8
// +     #1 = 16, align 8
// +     #2 = 16, align 8
// +     #3 = 16, align 8
// +     #4 = 16, align 8
// +     #5 = 16, align 8
// +
// + entry:
// +     store #0, ptr @4, align 8
// +     %0 = ptradd #0, 8
// +     store %0, i64 1, align 8
// +     store #2, ptr @0, align 8
// +     %1 = ptradd #2, 8
// +     store %1, i64 1, align 8
// +     call fastcc void s1(
// +         ptr @3,
// +         i64 1,
// +         ptr @2,
// +         i64 1,
// +         ptr @1,
// +         i64 1,
// +         ptr #2 byval i8[16])
// +     %2 = load ptr, #0, align 8
// +     %3 = ptradd #0, 8
// +     %4 = load i64, %3, align 8
// +     %5 = load ptr, #0, align 8
// +     %6 = ptradd #0, 8
// +     %7 = load i64, %6, align 8
// +     %8 = load ptr, #0, align 8
// +     %9 = ptradd #0, 8
// +     %10 = load i64, %9, align 8
// +     %11 = load ptr, #0, align 8
// +     %12 = ptradd #0, 8
// +     %13 = load i64, %12, align 8
// +     store #3, ptr %11, align 8
// +     %14 = ptradd #3, 8
// +     store %14, i64 %13, align 8
// +     call fastcc void s1(
// +         ptr %2,
// +         i64 %4,
// +         ptr %5,
// +         i64 %7,
// +         ptr %8,
// +         i64 %10,
// +         ptr #3 byval i8[16])
// +     %15 = load ptr, #0, align 8
// +     %16 = ptradd #0, 8
// +     %17 = load i64, %16, align 8
// +     %18 = load ptr, #0, align 8
// +     %19 = ptradd #0, 8
// +     %20 = load i64, %19, align 8
// +     call fastcc void s2(
// +         ptr #0 dereferenceable 16,
// +         ptr %15,
// +         i64 %17,
// +         ptr #0 dereferenceable 16,
// +         ptr %18,
// +         i64 %20)
// +     %21 = load ptr, #0, align 8
// +     %22 = ptradd #0, 8
// +     %23 = load i64, %22, align 8
// +     %24 = load ptr, #0, align 8
// +     %25 = ptradd #0, 8
// +     %26 = load i64, %25, align 8
// +     %27 = load ptr, #0, align 8
// +     %28 = ptradd #0, 8
// +     %29 = load i64, %28, align 8
// +     store #4, ptr %27, align 8
// +     %30 = ptradd #4, 8
// +     store %30, i64 %29, align 8
// +     %31 = load ptr, #0, align 8
// +     %32 = ptradd #0, 8
// +     %33 = load i64, %32, align 8
// +     store #5, ptr %31, align 8
// +     %34 = ptradd #5, 8
// +     store %34, i64 %33, align 8
// +     call fastcc void s3(
// +         ptr #0 dereferenceable 16,
// +         ptr %21,
// +         i64 %23,
// +         ptr #0 dereferenceable 16,
// +         ptr %24,
// +         i64 %26,
// +         ptr #4 byval i8[16],
// +         ptr #5 byval i8[16])
// +     %35 = call fastcc (i64, i64) s4()
// +     store #1, i64 %35:0, align 8
// +     %36 = ptradd #1, 8
// +     store %36, i64 %35:1, align 8
// +     ret
// + }
// +
// + proc s1 (
// +     ptr,
// +     i64,
// +     ptr,
// +     i64,
// +     ptr,
// +     i64,
// +     ptr byval i8[16],
// + ) external fastcc;
// +
// + proc s2 (
// +     ptr dereferenceable 16,
// +     ptr,
// +     i64,
// +     ptr dereferenceable 16,
// +     ptr,
// +     i64,
// + ) external fastcc;
// +
// + proc s3 (
// +     ptr dereferenceable 16,
// +     ptr,
// +     i64,
// +     ptr dereferenceable 16,
// +     ptr,
// +     i64,
// +     ptr byval i8[16],
// +     ptr byval i8[16],
// + ) external fastcc;
// +
// + proc s4 external fastcc -> (i64, i64);
// +
// + proc _S8closuresFvE private fastcc {
// +     #0 = 16, align 8
// +     #1 = 16, align 8
// +     #2 = 16, align 8
// +     #3 = 16, align 8
// +     #4 = 16, align 8
// +     #5 = 16, align 8
// +
// + entry:
// +     store #0, cx, align 8
// +     %0 = ptradd #0, 8
// +     store %0, ptr nil, align 8
// +     store #2, cx, align 8
// +     %1 = ptradd #2, 8
// +     store %1, ptr nil, align 8
// +     call fastcc void c1(
// +         cx,
// +         ptr nil,
// +         cx,
// +         ptr nil,
// +         cx,
// +         ptr nil,
// +         ptr #2 byval i8[16])
// +     %2 = load ptr, #0, align 8
// +     %3 = ptradd #0, 8
// +     %4 = load ptr, %3, align 8
// +     %5 = load ptr, #0, align 8
// +     %6 = ptradd #0, 8
// +     %7 = load ptr, %6, align 8
// +     %8 = load ptr, #0, align 8
// +     %9 = ptradd #0, 8
// +     %10 = load ptr, %9, align 8
// +     %11 = load ptr, #0, align 8
// +     %12 = ptradd #0, 8
// +     %13 = load ptr, %12, align 8
// +     store #3, ptr %11, align 8
// +     %14 = ptradd #3, 8
// +     store %14, ptr %13, align 8
// +     call fastcc void c1(
// +         ptr %2,
// +         ptr %4,
// +         ptr %5,
// +         ptr %7,
// +         ptr %8,
// +         ptr %10,
// +         ptr #3 byval i8[16])
// +     %15 = load ptr, #0, align 8
// +     %16 = ptradd #0, 8
// +     %17 = load ptr, %16, align 8
// +     %18 = load ptr, #0, align 8
// +     %19 = ptradd #0, 8
// +     %20 = load ptr, %19, align 8
// +     call fastcc void c2(
// +         ptr #0 dereferenceable 16,
// +         ptr %15,
// +         ptr %17,
// +         ptr #0 dereferenceable 16,
// +         ptr %18,
// +         ptr %20)
// +     %21 = load ptr, #0, align 8
// +     %22 = ptradd #0, 8
// +     %23 = load ptr, %22, align 8
// +     %24 = load ptr, #0, align 8
// +     %25 = ptradd #0, 8
// +     %26 = load ptr, %25, align 8
// +     %27 = load ptr, #0, align 8
// +     %28 = ptradd #0, 8
// +     %29 = load ptr, %28, align 8
// +     store #4, ptr %27, align 8
// +     %30 = ptradd #4, 8
// +     store %30, ptr %29, align 8
// +     %31 = load ptr, #0, align 8
// +     %32 = ptradd #0, 8
// +     %33 = load ptr, %32, align 8
// +     store #5, ptr %31, align 8
// +     %34 = ptradd #5, 8
// +     store %34, ptr %33, align 8
// +     call fastcc void c3(
// +         ptr #0 dereferenceable 16,
// +         ptr %21,
// +         ptr %23,
// +         ptr #0 dereferenceable 16,
// +         ptr %24,
// +         ptr %26,
// +         ptr #4 byval i8[16],
// +         ptr #5 byval i8[16])
// +     %35 = call fastcc (i64, i64) c4()
// +     store #1, i64 %35:0, align 8
// +     %36 = ptradd #1, 8
// +     store %36, i64 %35:1, align 8
// +     ret
// + }
// +
// + proc cx external fastcc;
// +
// + proc c1 (
// +     ptr,
// +     ptr,
// +     ptr,
// +     ptr,
// +     ptr,
// +     ptr,
// +     ptr byval i8[16],
// + ) external fastcc;
// +
// + proc c2 (
// +     ptr dereferenceable 16,
// +     ptr,
// +     ptr,
// +     ptr dereferenceable 16,
// +     ptr,
// +     ptr,
// + ) external fastcc;
// +
// + proc c3 (
// +     ptr dereferenceable 16,
// +     ptr,
// +     ptr,
// +     ptr dereferenceable 16,
// +     ptr,
// +     ptr,
// +     ptr byval i8[16],
// +     ptr byval i8[16],
// + ) external fastcc;
// +
// + proc c4 external fastcc -> (i64, i64);

//L * ; ModuleID = 'test'
//L + source_filename = "test"
//L + target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128"
//L + target triple = "x86_64-unknown-linux-gnu"
//L +
//L + @__srcc_str.4 = private constant [2 x i8] c"4\00", align 1
//L + @__srcc_str.3 = private constant [2 x i8] c"3\00", align 1
//L + @__srcc_str.2 = private constant [2 x i8] c"2\00", align 1
//L + @__srcc_str.1 = private constant [2 x i8] c"1\00", align 1
//L + @__srcc_str.0 = private constant [2 x i8] c"q\00", align 1
//L +
//L + ; Function Attrs: nounwind
//L + define fastcc void @__src_main() #0 {
//L +   ret void
//L + }
//L +
//L + ; Function Attrs: nounwind
//L + define private fastcc void @_S4intsFvE() #0 {
//L +   %1 = alloca i8, i64 16, align 16
//L +   %2 = alloca i8, i64 16, align 16
//L +   %3 = alloca i8, i64 16, align 16
//L +   %4 = alloca i8, i64 16, align 16
//L +   %5 = alloca i8, i64 16, align 16
//L +   %6 = alloca i8, i64 16, align 8
//L +   %7 = alloca i8, i64 16, align 8
//L +   %8 = alloca i8, i64 16, align 8
//L +   %9 = alloca i8, i64 16, align 8
//L +   %10 = alloca i8, i64 16, align 8
//L +   %11 = alloca i8, i64 16, align 8
//L +   %12 = alloca i8, i64 16, align 8
//L +   %13 = alloca i8, i64 16, align 8
//L +   %14 = alloca i8, i64 16, align 8
//L +   %15 = alloca i8, i64 16, align 8
//L +   %16 = alloca i8, i64 32, align 8
//L +   call void @f1(i64 1, i64 2, i64 3, i64 4, i64 5, i64 6, i64 7, i64 8)
//L +   call void @f2(i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8)
//L +   call void @f3(i17 signext 1, i17 signext 2, i17 signext 3, i17 signext 4, i17 signext 5, i17 signext 6, i17 signext 7, i17 signext 8)
//L +   call void @f4(i42 signext 1, i42 signext 2, i42 signext 3, i42 signext 4, i42 signext 5, i42 signext 6, i42 signext 7, i42 signext 8)
//L +   store i128 1, ptr %1, align 16
//L +   %17 = load i128, ptr %1, align 16
//L +   store i128 2, ptr %2, align 16
//L +   %18 = load i128, ptr %2, align 16
//L +   store i128 3, ptr %3, align 16
//L +   %19 = load i128, ptr %3, align 16
//L +   store i128 4, ptr %4, align 16
//L +   %20 = load i128, ptr %4, align 16
//L +   store i128 5, ptr %5, align 16
//L +   %21 = load i128, ptr %5, align 16
//L +   call void @f5(i128 %17, i128 %18, i128 %19, i128 %20, i128 %21)
//L +   store i128 1, ptr %6, align 8
//L +   %22 = load i64, ptr %6, align 8
//L +   %23 = getelementptr inbounds nuw i8, ptr %6, i32 8
//L +   %24 = load i64, ptr %23, align 8
//L +   store i128 2, ptr %7, align 8
//L +   %25 = load i64, ptr %7, align 8
//L +   %26 = getelementptr inbounds nuw i8, ptr %7, i32 8
//L +   %27 = load i64, ptr %26, align 8
//L +   store i128 3, ptr %8, align 8
//L +   %28 = load i64, ptr %8, align 8
//L +   %29 = getelementptr inbounds nuw i8, ptr %8, i32 8
//L +   %30 = load i64, ptr %29, align 8
//L +   store i128 4, ptr %9, align 8
//L +   store i128 5, ptr %10, align 8
//L +   call void @f6(i64 %22, i64 %24, i64 %25, i64 %27, i64 %28, i64 %30, ptr byval(i128) %9, ptr byval(i128) %10)
//L +   store i128 1, ptr %11, align 8
//L +   %31 = load i64, ptr %11, align 8
//L +   %32 = getelementptr inbounds nuw i8, ptr %11, i32 8
//L +   %33 = load i64, ptr %32, align 8
//L +   store i128 2, ptr %12, align 8
//L +   %34 = load i64, ptr %12, align 8
//L +   %35 = getelementptr inbounds nuw i8, ptr %12, i32 8
//L +   %36 = load i64, ptr %35, align 8
//L +   store i128 3, ptr %13, align 8
//L +   %37 = load i64, ptr %13, align 8
//L +   %38 = getelementptr inbounds nuw i8, ptr %13, i32 8
//L +   %39 = load i64, ptr %38, align 8
//L +   store i128 4, ptr %14, align 8
//L +   store i128 5, ptr %15, align 8
//L +   call void @f7(i64 %31, i64 %33, i64 %34, i64 %36, i64 %37, i64 %39, ptr byval(i128) %14, ptr byval(i128) %15)
//L +   store i256 1, ptr %16, align 8
//L +   call void @f8(ptr byval([32 x i8]) %16)
//L +   ret void
//L + }
//L +
//L + ; Function Attrs: nounwind
//L + declare void @f1(i64, i64, i64, i64, i64, i64, i64, i64) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare void @f2(i32, i32, i32, i32, i32, i32, i32, i32) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare void @f3(i17 signext, i17 signext, i17 signext, i17 signext, i17 signext, i17 signext, i17 signext, i17 signext) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare void @f4(i42 signext, i42 signext, i42 signext, i42 signext, i42 signext, i42 signext, i42 signext, i42 signext) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare void @f5(i128, i128, i128, i128, i128) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare void @f6(i64, i64, i64, i64, i64, i64, ptr byval(i128), ptr byval(i128)) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare void @f7(i64, i64, i64, i64, i64, i64, ptr byval(i128), ptr byval(i128)) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare void @f8(ptr byval([32 x i8])) #0
//L +
//L + ; Function Attrs: nounwind
//L + define private fastcc void @_S11int_lvaluesFvE() #0 {
//L +   %1 = alloca i8, i64 8, align 8
//L +   %2 = alloca i8, i64 4, align 4
//L +   %3 = alloca i8, i64 4, align 4
//L +   %4 = alloca i8, i64 8, align 8
//L +   %5 = alloca i8, i64 16, align 16
//L +   %6 = alloca i8, i64 16, align 8
//L +   %7 = alloca i8, i64 16, align 8
//L +   %8 = alloca i8, i64 32, align 8
//L +   %9 = alloca i8, i64 1, align 1
//L +   %10 = alloca i8, i64 1, align 1
//L +   %11 = alloca i8, i64 16, align 16
//L +   %12 = alloca i8, i64 16, align 8
//L +   %13 = alloca i8, i64 16, align 8
//L +   %14 = alloca i8, i64 32, align 8
//L +   store i64 1, ptr %1, align 8
//L +   store i32 1, ptr %2, align 4
//L +   store i32 1, ptr %3, align 4
//L +   store i64 1, ptr %4, align 8
//L +   store i128 1, ptr %5, align 16
//L +   store i128 1, ptr %6, align 8
//L +   store i128 1, ptr %7, align 8
//L +   store i256 1, ptr %8, align 8
//L +   store i8 0, ptr %9, align 1
//L +   store i8 -1, ptr %10, align 1
//L +   %15 = load i64, ptr %1, align 8
//L +   %16 = load i32, ptr %2, align 4
//L +   %17 = load i32, ptr %3, align 4
//L +   %18 = trunc i32 %17 to i17
//L +   %19 = load i64, ptr %4, align 8
//L +   %20 = trunc i64 %19 to i42
//L +   %21 = load i128, ptr %5, align 16
//L +   store i128 %21, ptr %11, align 16
//L +   %22 = load i128, ptr %11, align 16
//L +   %23 = load i128, ptr %6, align 8
//L +   %24 = trunc i128 %23 to i112
//L +   %25 = sext i112 %24 to i128
//L +   store i128 %25, ptr %12, align 8
//L +   %26 = load i128, ptr %7, align 8
//L +   %27 = trunc i128 %26 to i65
//L +   %28 = sext i65 %27 to i128
//L +   store i128 %28, ptr %13, align 8
//L +   %29 = load i256, ptr %8, align 8
//L +   store i256 %29, ptr %14, align 8
//L +   %30 = load i8, ptr %9, align 1
//L +   %31 = trunc i8 %30 to i1
//L +   %32 = load i8, ptr %10, align 1
//L +   %33 = trunc i8 %32 to i1
//L +   call void @f9(i64 %15, i32 %16, i17 signext %18, i42 signext %20, i128 %22, ptr byval(i128) %12, ptr byval(i128) %13, ptr byval([32 x i8]) %14, i1 signext %31, i1 zeroext %33)
//L +   ret void
//L + }
//L +
//L + ; Function Attrs: nounwind
//L + declare void @f9(i64, i32, i17 signext, i42 signext, i128, ptr byval(i128), ptr byval(i128), ptr byval([32 x i8]), i1 signext, i1 zeroext) #0
//L +
//L + ; Function Attrs: nounwind
//L + define private fastcc void @_S14struct_rvaluesFvE() #0 {
//L +   %1 = alloca i8, i64 4, align 4
//L +   %2 = alloca i8, i64 4, align 4
//L +   %3 = alloca i8, i64 4, align 4
//L +   %4 = alloca i8, i64 4, align 4
//L +   %5 = alloca i8, i64 4, align 4
//L +   %6 = alloca i8, i64 4, align 4
//L +   %7 = alloca i8, i64 4, align 4
//L +   %8 = alloca i8, i64 4, align 4
//L +   %9 = alloca i8, i64 8, align 4
//L +   %10 = alloca i8, i64 8, align 4
//L +   %11 = alloca i8, i64 8, align 4
//L +   %12 = alloca i8, i64 8, align 4
//L +   %13 = alloca i8, i64 8, align 4
//L +   %14 = alloca i8, i64 8, align 4
//L +   %15 = alloca i8, i64 8, align 4
//L +   %16 = alloca i8, i64 8, align 4
//L +   %17 = alloca i8, i64 16, align 8
//L +   %18 = alloca i8, i64 16, align 8
//L +   %19 = alloca i8, i64 16, align 8
//L +   %20 = alloca i8, i64 16, align 8
//L +   %21 = alloca i8, i64 8, align 4
//L +   %22 = alloca i8, i64 16, align 8
//L +   %23 = alloca i8, i64 16, align 8
//L +   %24 = alloca i8, i64 16, align 8
//L +   %25 = alloca i8, i64 16, align 8
//L +   %26 = alloca i8, i64 8, align 4
//L +   %27 = alloca i8, i64 8, align 4
//L +   %28 = alloca i8, i64 32, align 8
//L +   %29 = alloca i8, i64 4, align 4
//L +   %30 = alloca i8, i64 4, align 4
//L +   %31 = alloca i8, i64 4, align 4
//L +   %32 = alloca i8, i64 4, align 4
//L +   %33 = alloca i8, i64 4, align 4
//L +   %34 = alloca i8, i64 4, align 4
//L +   %35 = alloca i8, i64 4, align 4
//L +   %36 = alloca i8, i64 12, align 8
//L +   %37 = alloca i8, i64 12, align 8
//L +   %38 = alloca i8, i64 12, align 8
//L +   %39 = alloca i8, i64 12, align 8
//L +   %40 = alloca i8, i64 16, align 8
//L +   %41 = alloca i8, i64 16, align 8
//L +   %42 = alloca i8, i64 16, align 8
//L +   %43 = alloca i8, i64 16, align 8
//L +   %44 = alloca i8, i64 16, align 16
//L +   %45 = alloca i8, i64 16, align 16
//L +   %46 = alloca i8, i64 16, align 16
//L +   %47 = alloca i8, i64 16, align 16
//L +   store i32 1, ptr %1, align 4
//L +   %48 = load i32, ptr %1, align 4
//L +   store i32 1, ptr %2, align 4
//L +   %49 = load i32, ptr %2, align 4
//L +   store i32 1, ptr %3, align 4
//L +   %50 = load i32, ptr %3, align 4
//L +   store i32 1, ptr %4, align 4
//L +   %51 = load i32, ptr %4, align 4
//L +   store i32 1, ptr %5, align 4
//L +   %52 = load i32, ptr %5, align 4
//L +   store i32 1, ptr %6, align 4
//L +   %53 = load i32, ptr %6, align 4
//L +   store i32 1, ptr %7, align 4
//L +   %54 = load i32, ptr %7, align 4
//L +   store i32 1, ptr %8, align 4
//L +   %55 = load i32, ptr %8, align 4
//L +   call void @g1(i32 %48, i32 %49, i32 %50, i32 %51, i32 %52, i32 %53, i32 %54, i32 %55)
//L +   store i32 1, ptr %9, align 4
//L +   %56 = getelementptr inbounds nuw i8, ptr %9, i32 4
//L +   store i32 2, ptr %56, align 4
//L +   %57 = load i64, ptr %9, align 8
//L +   store i32 1, ptr %10, align 4
//L +   %58 = getelementptr inbounds nuw i8, ptr %10, i32 4
//L +   store i32 2, ptr %58, align 4
//L +   %59 = load i64, ptr %10, align 8
//L +   store i32 1, ptr %11, align 4
//L +   %60 = getelementptr inbounds nuw i8, ptr %11, i32 4
//L +   store i32 2, ptr %60, align 4
//L +   %61 = load i64, ptr %11, align 8
//L +   store i32 1, ptr %12, align 4
//L +   %62 = getelementptr inbounds nuw i8, ptr %12, i32 4
//L +   store i32 2, ptr %62, align 4
//L +   %63 = load i64, ptr %12, align 8
//L +   store i32 1, ptr %13, align 4
//L +   %64 = getelementptr inbounds nuw i8, ptr %13, i32 4
//L +   store i32 2, ptr %64, align 4
//L +   %65 = load i64, ptr %13, align 8
//L +   store i32 1, ptr %14, align 4
//L +   %66 = getelementptr inbounds nuw i8, ptr %14, i32 4
//L +   store i32 2, ptr %66, align 4
//L +   %67 = load i64, ptr %14, align 8
//L +   store i32 1, ptr %15, align 4
//L +   %68 = getelementptr inbounds nuw i8, ptr %15, i32 4
//L +   store i32 2, ptr %68, align 4
//L +   %69 = load i64, ptr %15, align 8
//L +   store i32 1, ptr %16, align 4
//L +   %70 = getelementptr inbounds nuw i8, ptr %16, i32 4
//L +   store i32 2, ptr %70, align 4
//L +   %71 = load i64, ptr %16, align 8
//L +   call void @g2(i64 %57, i64 %59, i64 %61, i64 %63, i64 %65, i64 %67, i64 %69, i64 %71)
//L +   store i64 1, ptr %17, align 8
//L +   %72 = getelementptr inbounds nuw i8, ptr %17, i32 8
//L +   store i64 2, ptr %72, align 8
//L +   %73 = load i64, ptr %17, align 8
//L +   %74 = getelementptr inbounds nuw i8, ptr %17, i32 8
//L +   %75 = load i64, ptr %74, align 8
//L +   store i64 1, ptr %18, align 8
//L +   %76 = getelementptr inbounds nuw i8, ptr %18, i32 8
//L +   store i64 2, ptr %76, align 8
//L +   %77 = load i64, ptr %18, align 8
//L +   %78 = getelementptr inbounds nuw i8, ptr %18, i32 8
//L +   %79 = load i64, ptr %78, align 8
//L +   store i64 1, ptr %19, align 8
//L +   %80 = getelementptr inbounds nuw i8, ptr %19, i32 8
//L +   store i64 2, ptr %80, align 8
//L +   %81 = load i64, ptr %19, align 8
//L +   %82 = getelementptr inbounds nuw i8, ptr %19, i32 8
//L +   %83 = load i64, ptr %82, align 8
//L +   store i64 1, ptr %20, align 8
//L +   %84 = getelementptr inbounds nuw i8, ptr %20, i32 8
//L +   store i64 2, ptr %84, align 8
//L +   call void @g3(i64 %73, i64 %75, i64 %77, i64 %79, i64 %81, i64 %83, ptr byval([16 x i8]) %20)
//L +   store i32 1, ptr %21, align 4
//L +   %85 = getelementptr inbounds nuw i8, ptr %21, i32 4
//L +   store i32 2, ptr %85, align 4
//L +   %86 = load i64, ptr %21, align 8
//L +   store i64 1, ptr %22, align 8
//L +   %87 = getelementptr inbounds nuw i8, ptr %22, i32 8
//L +   store i64 2, ptr %87, align 8
//L +   %88 = load i64, ptr %22, align 8
//L +   %89 = getelementptr inbounds nuw i8, ptr %22, i32 8
//L +   %90 = load i64, ptr %89, align 8
//L +   store i64 1, ptr %23, align 8
//L +   %91 = getelementptr inbounds nuw i8, ptr %23, i32 8
//L +   store i64 2, ptr %91, align 8
//L +   %92 = load i64, ptr %23, align 8
//L +   %93 = getelementptr inbounds nuw i8, ptr %23, i32 8
//L +   %94 = load i64, ptr %93, align 8
//L +   store i64 1, ptr %24, align 8
//L +   %95 = getelementptr inbounds nuw i8, ptr %24, i32 8
//L +   store i64 2, ptr %95, align 8
//L +   store i64 1, ptr %25, align 8
//L +   %96 = getelementptr inbounds nuw i8, ptr %25, i32 8
//L +   store i64 2, ptr %96, align 8
//L +   store i32 1, ptr %26, align 4
//L +   %97 = getelementptr inbounds nuw i8, ptr %26, i32 4
//L +   store i32 2, ptr %97, align 4
//L +   %98 = load i64, ptr %26, align 8
//L +   store i32 1, ptr %27, align 4
//L +   %99 = getelementptr inbounds nuw i8, ptr %27, i32 4
//L +   store i32 2, ptr %99, align 4
//L +   %100 = load i64, ptr %27, align 8
//L +   call void @g4(i64 %86, i64 %88, i64 %90, i64 %92, i64 %94, ptr byval([16 x i8]) %24, ptr byval([16 x i8]) %25, i64 %98, i64 %100)
//L +   store i256 1, ptr %28, align 8
//L +   store i32 1, ptr %29, align 4
//L +   %101 = load i32, ptr %29, align 4
//L +   store i32 1, ptr %30, align 4
//L +   %102 = load i32, ptr %30, align 4
//L +   store i32 1, ptr %31, align 4
//L +   %103 = load i32, ptr %31, align 4
//L +   store i32 1, ptr %32, align 4
//L +   %104 = load i32, ptr %32, align 4
//L +   store i32 1, ptr %33, align 4
//L +   %105 = load i32, ptr %33, align 4
//L +   store i32 1, ptr %34, align 4
//L +   %106 = load i32, ptr %34, align 4
//L +   store i32 1, ptr %35, align 4
//L +   %107 = load i32, ptr %35, align 4
//L +   call void @g5(ptr byval([32 x i8]) %28, i32 %101, i32 %102, i32 %103, i32 %104, i32 %105, i32 %106, i32 %107)
//L +   store i64 1, ptr %36, align 8
//L +   %108 = getelementptr inbounds nuw i8, ptr %36, i32 8
//L +   store i32 2, ptr %108, align 4
//L +   %109 = load i64, ptr %36, align 8
//L +   %110 = getelementptr inbounds nuw i8, ptr %36, i32 8
//L +   %111 = load i32, ptr %110, align 4
//L +   store i64 1, ptr %37, align 8
//L +   %112 = getelementptr inbounds nuw i8, ptr %37, i32 8
//L +   store i32 2, ptr %112, align 4
//L +   %113 = load i64, ptr %37, align 8
//L +   %114 = getelementptr inbounds nuw i8, ptr %37, i32 8
//L +   %115 = load i32, ptr %114, align 4
//L +   store i64 1, ptr %38, align 8
//L +   %116 = getelementptr inbounds nuw i8, ptr %38, i32 8
//L +   store i32 2, ptr %116, align 4
//L +   %117 = load i64, ptr %38, align 8
//L +   %118 = getelementptr inbounds nuw i8, ptr %38, i32 8
//L +   %119 = load i32, ptr %118, align 4
//L +   store i64 1, ptr %39, align 8
//L +   %120 = getelementptr inbounds nuw i8, ptr %39, i32 8
//L +   store i32 2, ptr %120, align 4
//L +   call void @g6(i64 %109, i32 %111, i64 %113, i32 %115, i64 %117, i32 %119, ptr byval([12 x i8]) %39)
//L +   store i32 1, ptr %40, align 4
//L +   %121 = getelementptr inbounds nuw i8, ptr %40, i32 8
//L +   store i64 2, ptr %121, align 8
//L +   %122 = load i64, ptr %40, align 8
//L +   %123 = getelementptr inbounds nuw i8, ptr %40, i32 8
//L +   %124 = load i64, ptr %123, align 8
//L +   store i32 1, ptr %41, align 4
//L +   %125 = getelementptr inbounds nuw i8, ptr %41, i32 8
//L +   store i64 2, ptr %125, align 8
//L +   %126 = load i64, ptr %41, align 8
//L +   %127 = getelementptr inbounds nuw i8, ptr %41, i32 8
//L +   %128 = load i64, ptr %127, align 8
//L +   store i32 1, ptr %42, align 4
//L +   %129 = getelementptr inbounds nuw i8, ptr %42, i32 8
//L +   store i64 2, ptr %129, align 8
//L +   %130 = load i64, ptr %42, align 8
//L +   %131 = getelementptr inbounds nuw i8, ptr %42, i32 8
//L +   %132 = load i64, ptr %131, align 8
//L +   store i32 1, ptr %43, align 4
//L +   %133 = getelementptr inbounds nuw i8, ptr %43, i32 8
//L +   store i64 2, ptr %133, align 8
//L +   call void @g7(i64 %122, i64 %124, i64 %126, i64 %128, i64 %130, i64 %132, ptr byval([16 x i8]) %43)
//L +   store i128 1, ptr %44, align 16
//L +   %134 = load i64, ptr %44, align 8
//L +   %135 = getelementptr inbounds nuw i8, ptr %44, i32 8
//L +   %136 = load i64, ptr %135, align 8
//L +   store i128 2, ptr %45, align 16
//L +   %137 = load i64, ptr %45, align 8
//L +   %138 = getelementptr inbounds nuw i8, ptr %45, i32 8
//L +   %139 = load i64, ptr %138, align 8
//L +   store i128 3, ptr %46, align 16
//L +   %140 = load i64, ptr %46, align 8
//L +   %141 = getelementptr inbounds nuw i8, ptr %46, i32 8
//L +   %142 = load i64, ptr %141, align 8
//L +   store i128 4, ptr %47, align 16
//L +   call void @g8(i64 %134, i64 %136, i64 %137, i64 %139, i64 %140, i64 %142, ptr byval([16 x i8]) %47)
//L +   ret void
//L + }
//L +
//L + ; Function Attrs: nounwind
//L + declare void @g1(i32, i32, i32, i32, i32, i32, i32, i32) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare void @g2(i64, i64, i64, i64, i64, i64, i64, i64) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare void @g3(i64, i64, i64, i64, i64, i64, ptr byval([16 x i8])) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare void @g4(i64, i64, i64, i64, i64, ptr byval([16 x i8]), ptr byval([16 x i8]), i64, i64) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare void @g5(ptr byval([32 x i8]), i32, i32, i32, i32, i32, i32, i32) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare void @g6(i64, i32, i64, i32, i64, i32, ptr byval([12 x i8])) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare void @g7(i64, i64, i64, i64, i64, i64, ptr byval([16 x i8])) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare void @g8(i64, i64, i64, i64, i64, i64, ptr byval([16 x i8])) #0
//L +
//L + ; Function Attrs: nounwind
//L + define private fastcc void @_S14struct_lvaluesFvE() #0 {
//L +   %1 = alloca i8, i64 4, align 4
//L +   %2 = alloca i8, i64 8, align 4
//L +   %3 = alloca i8, i64 16, align 8
//L +   %4 = alloca i8, i64 12, align 8
//L +   %5 = alloca i8, i64 16, align 8
//L +   %6 = alloca i8, i64 16, align 16
//L +   %7 = alloca i8, i64 4, align 4
//L +   %8 = alloca i8, i64 4, align 4
//L +   %9 = alloca i8, i64 4, align 4
//L +   %10 = alloca i8, i64 4, align 4
//L +   %11 = alloca i8, i64 4, align 4
//L +   %12 = alloca i8, i64 4, align 4
//L +   %13 = alloca i8, i64 4, align 4
//L +   %14 = alloca i8, i64 4, align 4
//L +   %15 = alloca i8, i64 8, align 4
//L +   %16 = alloca i8, i64 8, align 4
//L +   %17 = alloca i8, i64 8, align 4
//L +   %18 = alloca i8, i64 8, align 4
//L +   %19 = alloca i8, i64 8, align 4
//L +   %20 = alloca i8, i64 8, align 4
//L +   %21 = alloca i8, i64 8, align 4
//L +   %22 = alloca i8, i64 8, align 4
//L +   %23 = alloca i8, i64 16, align 8
//L +   %24 = alloca i8, i64 16, align 8
//L +   %25 = alloca i8, i64 16, align 8
//L +   %26 = alloca i8, i64 16, align 8
//L +   %27 = alloca i8, i64 8, align 4
//L +   %28 = alloca i8, i64 16, align 8
//L +   %29 = alloca i8, i64 16, align 8
//L +   %30 = alloca i8, i64 16, align 8
//L +   %31 = alloca i8, i64 16, align 8
//L +   %32 = alloca i8, i64 8, align 4
//L +   %33 = alloca i8, i64 8, align 4
//L +   %34 = alloca i8, i64 32, align 8
//L +   %35 = alloca i8, i64 4, align 4
//L +   %36 = alloca i8, i64 4, align 4
//L +   %37 = alloca i8, i64 4, align 4
//L +   %38 = alloca i8, i64 4, align 4
//L +   %39 = alloca i8, i64 4, align 4
//L +   %40 = alloca i8, i64 4, align 4
//L +   %41 = alloca i8, i64 4, align 4
//L +   %42 = alloca i8, i64 12, align 8
//L +   %43 = alloca i8, i64 12, align 8
//L +   %44 = alloca i8, i64 12, align 8
//L +   %45 = alloca i8, i64 12, align 8
//L +   %46 = alloca i8, i64 16, align 8
//L +   %47 = alloca i8, i64 16, align 8
//L +   %48 = alloca i8, i64 16, align 8
//L +   %49 = alloca i8, i64 16, align 8
//L +   %50 = alloca i8, i64 16, align 16
//L +   %51 = alloca i8, i64 16, align 16
//L +   %52 = alloca i8, i64 16, align 16
//L +   %53 = alloca i8, i64 16, align 16
//L +   store i32 1, ptr %1, align 4
//L +   store i32 1, ptr %2, align 4
//L +   %54 = getelementptr inbounds nuw i8, ptr %2, i32 4
//L +   store i32 2, ptr %54, align 4
//L +   store i64 1, ptr %3, align 8
//L +   %55 = getelementptr inbounds nuw i8, ptr %3, i32 8
//L +   store i64 2, ptr %55, align 8
//L +   store i64 1, ptr %4, align 8
//L +   %56 = getelementptr inbounds nuw i8, ptr %4, i32 8
//L +   store i32 2, ptr %56, align 4
//L +   store i32 1, ptr %5, align 4
//L +   %57 = getelementptr inbounds nuw i8, ptr %5, i32 8
//L +   store i64 2, ptr %57, align 8
//L +   store i128 1, ptr %6, align 16
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %7, ptr %1, i64 4, i1 false)
//L +   %58 = load i32, ptr %7, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %8, ptr %1, i64 4, i1 false)
//L +   %59 = load i32, ptr %8, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %9, ptr %1, i64 4, i1 false)
//L +   %60 = load i32, ptr %9, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %10, ptr %1, i64 4, i1 false)
//L +   %61 = load i32, ptr %10, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %11, ptr %1, i64 4, i1 false)
//L +   %62 = load i32, ptr %11, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %12, ptr %1, i64 4, i1 false)
//L +   %63 = load i32, ptr %12, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %13, ptr %1, i64 4, i1 false)
//L +   %64 = load i32, ptr %13, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %14, ptr %1, i64 4, i1 false)
//L +   %65 = load i32, ptr %14, align 4
//L +   call void @g1(i32 %58, i32 %59, i32 %60, i32 %61, i32 %62, i32 %63, i32 %64, i32 %65)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %15, ptr %2, i64 8, i1 false)
//L +   %66 = load i64, ptr %15, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %16, ptr %2, i64 8, i1 false)
//L +   %67 = load i64, ptr %16, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %17, ptr %2, i64 8, i1 false)
//L +   %68 = load i64, ptr %17, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %18, ptr %2, i64 8, i1 false)
//L +   %69 = load i64, ptr %18, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %19, ptr %2, i64 8, i1 false)
//L +   %70 = load i64, ptr %19, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %20, ptr %2, i64 8, i1 false)
//L +   %71 = load i64, ptr %20, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %21, ptr %2, i64 8, i1 false)
//L +   %72 = load i64, ptr %21, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %22, ptr %2, i64 8, i1 false)
//L +   %73 = load i64, ptr %22, align 8
//L +   call void @g2(i64 %66, i64 %67, i64 %68, i64 %69, i64 %70, i64 %71, i64 %72, i64 %73)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %23, ptr %3, i64 16, i1 false)
//L +   %74 = load i64, ptr %23, align 8
//L +   %75 = getelementptr inbounds nuw i8, ptr %23, i32 8
//L +   %76 = load i64, ptr %75, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %24, ptr %3, i64 16, i1 false)
//L +   %77 = load i64, ptr %24, align 8
//L +   %78 = getelementptr inbounds nuw i8, ptr %24, i32 8
//L +   %79 = load i64, ptr %78, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %25, ptr %3, i64 16, i1 false)
//L +   %80 = load i64, ptr %25, align 8
//L +   %81 = getelementptr inbounds nuw i8, ptr %25, i32 8
//L +   %82 = load i64, ptr %81, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %26, ptr %3, i64 16, i1 false)
//L +   call void @g3(i64 %74, i64 %76, i64 %77, i64 %79, i64 %80, i64 %82, ptr byval([16 x i8]) %26)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %27, ptr %2, i64 8, i1 false)
//L +   %83 = load i64, ptr %27, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %28, ptr %3, i64 16, i1 false)
//L +   %84 = load i64, ptr %28, align 8
//L +   %85 = getelementptr inbounds nuw i8, ptr %28, i32 8
//L +   %86 = load i64, ptr %85, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %29, ptr %3, i64 16, i1 false)
//L +   %87 = load i64, ptr %29, align 8
//L +   %88 = getelementptr inbounds nuw i8, ptr %29, i32 8
//L +   %89 = load i64, ptr %88, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %30, ptr %3, i64 16, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %31, ptr %3, i64 16, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %32, ptr %2, i64 8, i1 false)
//L +   %90 = load i64, ptr %32, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %33, ptr %2, i64 8, i1 false)
//L +   %91 = load i64, ptr %33, align 8
//L +   call void @g4(i64 %83, i64 %84, i64 %86, i64 %87, i64 %89, ptr byval([16 x i8]) %30, ptr byval([16 x i8]) %31, i64 %90, i64 %91)
//L +   store i256 1, ptr %34, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %35, ptr %1, i64 4, i1 false)
//L +   %92 = load i32, ptr %35, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %36, ptr %1, i64 4, i1 false)
//L +   %93 = load i32, ptr %36, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %37, ptr %1, i64 4, i1 false)
//L +   %94 = load i32, ptr %37, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %38, ptr %1, i64 4, i1 false)
//L +   %95 = load i32, ptr %38, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %39, ptr %1, i64 4, i1 false)
//L +   %96 = load i32, ptr %39, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %40, ptr %1, i64 4, i1 false)
//L +   %97 = load i32, ptr %40, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %41, ptr %1, i64 4, i1 false)
//L +   %98 = load i32, ptr %41, align 4
//L +   call void @g5(ptr byval([32 x i8]) %34, i32 %92, i32 %93, i32 %94, i32 %95, i32 %96, i32 %97, i32 %98)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %42, ptr %4, i64 12, i1 false)
//L +   %99 = load i64, ptr %42, align 8
//L +   %100 = getelementptr inbounds nuw i8, ptr %42, i32 8
//L +   %101 = load i32, ptr %100, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %43, ptr %4, i64 12, i1 false)
//L +   %102 = load i64, ptr %43, align 8
//L +   %103 = getelementptr inbounds nuw i8, ptr %43, i32 8
//L +   %104 = load i32, ptr %103, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %44, ptr %4, i64 12, i1 false)
//L +   %105 = load i64, ptr %44, align 8
//L +   %106 = getelementptr inbounds nuw i8, ptr %44, i32 8
//L +   %107 = load i32, ptr %106, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %45, ptr %4, i64 12, i1 false)
//L +   call void @g6(i64 %99, i32 %101, i64 %102, i32 %104, i64 %105, i32 %107, ptr byval([12 x i8]) %45)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %46, ptr %5, i64 16, i1 false)
//L +   %108 = load i64, ptr %46, align 8
//L +   %109 = getelementptr inbounds nuw i8, ptr %46, i32 8
//L +   %110 = load i64, ptr %109, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %47, ptr %5, i64 16, i1 false)
//L +   %111 = load i64, ptr %47, align 8
//L +   %112 = getelementptr inbounds nuw i8, ptr %47, i32 8
//L +   %113 = load i64, ptr %112, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %48, ptr %5, i64 16, i1 false)
//L +   %114 = load i64, ptr %48, align 8
//L +   %115 = getelementptr inbounds nuw i8, ptr %48, i32 8
//L +   %116 = load i64, ptr %115, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %49, ptr %5, i64 16, i1 false)
//L +   call void @g7(i64 %108, i64 %110, i64 %111, i64 %113, i64 %114, i64 %116, ptr byval([16 x i8]) %49)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %50, ptr %6, i64 16, i1 false)
//L +   %117 = load i64, ptr %50, align 8
//L +   %118 = getelementptr inbounds nuw i8, ptr %50, i32 8
//L +   %119 = load i64, ptr %118, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %51, ptr %6, i64 16, i1 false)
//L +   %120 = load i64, ptr %51, align 8
//L +   %121 = getelementptr inbounds nuw i8, ptr %51, i32 8
//L +   %122 = load i64, ptr %121, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %52, ptr %6, i64 16, i1 false)
//L +   %123 = load i64, ptr %52, align 8
//L +   %124 = getelementptr inbounds nuw i8, ptr %52, i32 8
//L +   %125 = load i64, ptr %124, align 8
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %53, ptr %6, i64 16, i1 false)
//L +   call void @g8(i64 %117, i64 %119, i64 %120, i64 %122, i64 %123, i64 %125, ptr byval([16 x i8]) %53)
//L +   ret void
//L + }
//L +
//L + ; Function Attrs: nounwind
//L + define private fastcc void @_S6in_outFvE() #0 {
//L +   %1 = alloca i8, i64 4, align 4
//L +   %2 = alloca i8, i64 4, align 4
//L +   %3 = alloca i8, i64 4, align 4
//L +   %4 = alloca i8, i64 4, align 4
//L +   %5 = alloca i8, i64 4, align 4
//L +   store i32 1, ptr %1, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %2, ptr %1, i64 4, i1 false)
//L +   %6 = load i32, ptr %2, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %3, ptr %1, i64 4, i1 false)
//L +   %7 = load i32, ptr %3, align 4
//L +   call fastcc void @h1(ptr dereferenceable(4) %1, ptr dereferenceable(4) %1, ptr dereferenceable(4) %1, ptr dereferenceable(4) %1, ptr dereferenceable(4) %1, i32 %6, i32 %7, ptr dereferenceable(4) %1)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %4, ptr %1, i64 4, i1 false)
//L +   %8 = load i32, ptr %4, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %5, ptr %1, i64 4, i1 false)
//L +   %9 = load i32, ptr %5, align 4
//L +   call fastcc void @h2(ptr dereferenceable(4) %1, ptr dereferenceable(4) %1, ptr dereferenceable(4) %1, ptr dereferenceable(4) %1, ptr dereferenceable(4) %1, i32 %8, i32 %9, ptr dereferenceable(4) %1)
//L +   ret void
//L + }
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc void @h1(ptr dereferenceable(4), ptr dereferenceable(4), ptr dereferenceable(4), ptr dereferenceable(4), ptr dereferenceable(4), i32, i32, ptr dereferenceable(4)) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc void @h2(ptr dereferenceable(4), ptr dereferenceable(4), ptr dereferenceable(4), ptr dereferenceable(4), ptr dereferenceable(4), i32, i32, ptr dereferenceable(4)) #0
//L +
//L + ; Function Attrs: nounwind
//L + define private fastcc void @_S13in_move_smallFvE() #0 {
//L +   %1 = alloca i8, i64 4, align 4
//L +   %2 = alloca i8, i64 4, align 4
//L +   %3 = alloca i8, i64 4, align 4
//L +   %4 = alloca i8, i64 4, align 4
//L +   %5 = alloca i8, i64 4, align 4
//L +   %6 = alloca i8, i64 4, align 4
//L +   %7 = alloca i8, i64 4, align 4
//L +   %8 = alloca i8, i64 4, align 4
//L +   %9 = alloca i8, i64 4, align 4
//L +   %10 = alloca i8, i64 4, align 4
//L +   %11 = alloca i8, i64 4, align 4
//L +   %12 = alloca i8, i64 4, align 4
//L +   %13 = alloca i8, i64 4, align 4
//L +   %14 = alloca i8, i64 4, align 4
//L +   %15 = alloca i8, i64 4, align 4
//L +   %16 = alloca i8, i64 4, align 4
//L +   %17 = alloca i8, i64 4, align 4
//L +   store i32 1, ptr %1, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %2, ptr %1, i64 4, i1 false)
//L +   %18 = load i32, ptr %2, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %3, ptr %1, i64 4, i1 false)
//L +   %19 = load i32, ptr %3, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %4, ptr %1, i64 4, i1 false)
//L +   %20 = load i32, ptr %4, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %5, ptr %1, i64 4, i1 false)
//L +   %21 = load i32, ptr %5, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %6, ptr %1, i64 4, i1 false)
//L +   %22 = load i32, ptr %6, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %7, ptr %1, i64 4, i1 false)
//L +   %23 = load i32, ptr %7, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %8, ptr %1, i64 4, i1 false)
//L +   %24 = load i32, ptr %8, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %9, ptr %1, i64 4, i1 false)
//L +   %25 = load i32, ptr %9, align 4
//L +   call fastcc void @h3(i32 %18, i32 %19, i32 %20, i32 %21, i32 %22, i32 %23, i32 %24, i32 %25)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %10, ptr %1, i64 4, i1 false)
//L +   %26 = load i32, ptr %10, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %11, ptr %1, i64 4, i1 false)
//L +   %27 = load i32, ptr %11, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %12, ptr %1, i64 4, i1 false)
//L +   %28 = load i32, ptr %12, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %13, ptr %1, i64 4, i1 false)
//L +   %29 = load i32, ptr %13, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %14, ptr %1, i64 4, i1 false)
//L +   %30 = load i32, ptr %14, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %15, ptr %1, i64 4, i1 false)
//L +   %31 = load i32, ptr %15, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %16, ptr %1, i64 4, i1 false)
//L +   %32 = load i32, ptr %16, align 4
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %17, ptr %1, i64 4, i1 false)
//L +   %33 = load i32, ptr %17, align 4
//L +   call fastcc void @h4(i32 %26, i32 %27, i32 %28, i32 %29, i32 %30, i32 %31, i32 %32, i32 %33)
//L +   ret void
//L + }
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc void @h3(i32, i32, i32, i32, i32, i32, i32, i32) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc void @h4(i32, i32, i32, i32, i32, i32, i32, i32) #0
//L +
//L + ; Function Attrs: nounwind
//L + define private fastcc void @_S10big_structFvE() #0 {
//L +   %1 = alloca i8, i64 400, align 8
//L +   %2 = alloca i8, i64 400, align 8
//L +   %3 = alloca i8, i64 400, align 8
//L +   %4 = alloca i8, i64 400, align 8
//L +   %5 = alloca i8, i64 400, align 8
//L +   %6 = alloca i8, i64 400, align 8
//L +   %7 = alloca i8, i64 400, align 8
//L +   %8 = alloca i8, i64 400, align 8
//L +   %9 = alloca i8, i64 400, align 8
//L +   %10 = alloca i8, i64 4, align 4
//L +   %11 = alloca i8, i64 400, align 8
//L +   %12 = alloca i8, i64 400, align 8
//L +   %13 = alloca i8, i64 400, align 8
//L +   %14 = alloca i8, i64 400, align 8
//L +   %15 = alloca i8, i64 400, align 8
//L +   %16 = alloca i8, i64 400, align 8
//L +   %17 = alloca i8, i64 400, align 8
//L +   %18 = alloca i8, i64 400, align 8
//L +   %19 = alloca i8, i64 4, align 4
//L +   %20 = alloca i8, i64 400, align 8
//L +   %21 = alloca i8, i64 400, align 8
//L +   %22 = alloca i8, i64 400, align 8
//L +   %23 = alloca i8, i64 400, align 8
//L +   %24 = alloca i8, i64 400, align 8
//L +   %25 = alloca i8, i64 400, align 8
//L +   %26 = alloca i8, i64 400, align 8
//L +   %27 = alloca i8, i64 400, align 8
//L +   %28 = alloca i8, i64 4, align 4
//L +   %29 = alloca i8, i64 400, align 8
//L +   %30 = alloca i8, i64 4, align 4
//L +   %31 = alloca i8, i64 400, align 8
//L +   %32 = alloca i8, i64 4, align 4
//L +   call void @llvm.memset.p0.i64(ptr %1, i8 0, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %2, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %3, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %4, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %5, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %6, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %7, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %8, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %9, ptr %1, i64 400, i1 false)
//L +   store i32 42, ptr %10, align 4
//L +   %33 = load i32, ptr %10, align 4
//L +   call fastcc void @big1(ptr dereferenceable(400) %2, ptr dereferenceable(400) %3, ptr dereferenceable(400) %4, ptr dereferenceable(400) %5, ptr dereferenceable(400) %6, ptr dereferenceable(400) %7, ptr byval([400 x i8]) %8, ptr dereferenceable(400) %9, i32 %33)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %11, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %12, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %13, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %14, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %15, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %16, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %17, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %18, ptr %1, i64 400, i1 false)
//L +   store i32 42, ptr %19, align 4
//L +   %34 = load i32, ptr %19, align 4
//L +   call fastcc void @big2(ptr byval([400 x i8]) %11, ptr byval([400 x i8]) %12, ptr byval([400 x i8]) %13, ptr byval([400 x i8]) %14, ptr byval([400 x i8]) %15, ptr byval([400 x i8]) %16, ptr byval([400 x i8]) %17, ptr byval([400 x i8]) %18, i32 %34)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %20, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %21, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %22, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %23, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %24, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %25, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %26, ptr %1, i64 400, i1 false)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %27, ptr %1, i64 400, i1 false)
//L +   store i32 42, ptr %28, align 4
//L +   %35 = load i32, ptr %28, align 4
//L +   call fastcc void @big3(ptr byval([400 x i8]) %20, ptr byval([400 x i8]) %21, ptr byval([400 x i8]) %22, ptr byval([400 x i8]) %23, ptr byval([400 x i8]) %24, ptr byval([400 x i8]) %25, ptr byval([400 x i8]) %26, ptr byval([400 x i8]) %27, i32 %35)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %29, ptr %1, i64 400, i1 false)
//L +   store i32 42, ptr %30, align 4
//L +   %36 = load i32, ptr %30, align 4
//L +   call fastcc void @big4(ptr dereferenceable(400) %1, ptr dereferenceable(400) %1, ptr dereferenceable(400) %1, ptr dereferenceable(400) %1, ptr dereferenceable(400) %1, ptr dereferenceable(400) %1, ptr byval([400 x i8]) %29, ptr dereferenceable(400) %1, i32 %36)
//L +   call void @llvm.memcpy.p0.p0.i64(ptr %31, ptr %1, i64 400, i1 false)
//L +   store i32 42, ptr %32, align 4
//L +   %37 = load i32, ptr %32, align 4
//L +   call fastcc void @big5(ptr dereferenceable(400) %1, ptr dereferenceable(400) %1, ptr dereferenceable(400) %1, ptr dereferenceable(400) %1, ptr dereferenceable(400) %1, ptr dereferenceable(400) %1, ptr byval([400 x i8]) %31, ptr dereferenceable(400) %1, i32 %37)
//L +   ret void
//L + }
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc void @big1(ptr dereferenceable(400), ptr dereferenceable(400), ptr dereferenceable(400), ptr dereferenceable(400), ptr dereferenceable(400), ptr dereferenceable(400), ptr byval([400 x i8]), ptr dereferenceable(400), i32) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc void @big2(ptr byval([400 x i8]), ptr byval([400 x i8]), ptr byval([400 x i8]), ptr byval([400 x i8]), ptr byval([400 x i8]), ptr byval([400 x i8]), ptr byval([400 x i8]), ptr byval([400 x i8]), i32) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc void @big3(ptr byval([400 x i8]), ptr byval([400 x i8]), ptr byval([400 x i8]), ptr byval([400 x i8]), ptr byval([400 x i8]), ptr byval([400 x i8]), ptr byval([400 x i8]), ptr byval([400 x i8]), i32) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc void @big4(ptr dereferenceable(400), ptr dereferenceable(400), ptr dereferenceable(400), ptr dereferenceable(400), ptr dereferenceable(400), ptr dereferenceable(400), ptr byval([400 x i8]), ptr dereferenceable(400), i32) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc void @big5(ptr dereferenceable(400), ptr dereferenceable(400), ptr dereferenceable(400), ptr dereferenceable(400), ptr dereferenceable(400), ptr dereferenceable(400), ptr byval([400 x i8]), ptr dereferenceable(400), i32) #0
//L +
//L + ; Function Attrs: nounwind
//L + define private fastcc void @_S7returnsFvE() #0 {
//L +   %1 = alloca i8, i64 1, align 1
//L +   %2 = alloca i8, i64 1, align 1
//L +   %3 = alloca i8, i64 1, align 1
//L +   %4 = alloca i8, i64 1, align 1
//L +   %5 = alloca i8, i64 1, align 1
//L +   %6 = alloca i8, i64 2, align 2
//L +   %7 = alloca i8, i64 4, align 4
//L +   %8 = alloca i8, i64 4, align 4
//L +   %9 = alloca i8, i64 8, align 8
//L +   %10 = alloca i8, i64 8, align 8
//L +   %11 = alloca i8, i64 16, align 8
//L +   %12 = alloca i8, i64 16, align 8
//L +   %13 = alloca i8, i64 16, align 16
//L +   %14 = alloca i8, i64 24, align 8
//L +   %15 = alloca i8, i64 4, align 4
//L +   %16 = alloca i8, i64 8, align 4
//L +   %17 = alloca i8, i64 16, align 8
//L +   %18 = alloca i8, i64 400, align 8
//L +   %19 = alloca i8, i64 4, align 2
//L +   %20 = alloca i8, i64 2, align 1
//L +   %21 = alloca i8, i64 2, align 1
//L +   %22 = alloca i8, i64 16, align 8
//L +   %23 = alloca i8, i64 16, align 8
//L +   %24 = alloca i8, i64 24, align 8
//L +   %25 = call zeroext i1 @r1()
//L +   %26 = sext i1 %25 to i8
//L +   store i8 %26, ptr %1, align 1
//L +   %27 = call signext i1 @r2()
//L +   %28 = sext i1 %27 to i8
//L +   store i8 %28, ptr %2, align 1
//L +   %29 = call signext i4 @r3()
//L +   %30 = sext i4 %29 to i8
//L +   store i8 %30, ptr %3, align 1
//L +   %31 = call signext i7 @r4()
//L +   %32 = sext i7 %31 to i8
//L +   store i8 %32, ptr %4, align 1
//L +   %33 = call i8 @r5()
//L +   store i8 %33, ptr %5, align 1
//L +   %34 = call i16 @r6()
//L +   store i16 %34, ptr %6, align 2
//L +   %35 = call signext i17 @r7()
//L +   %36 = sext i17 %35 to i32
//L +   store i32 %36, ptr %7, align 4
//L +   %37 = call i32 @r8()
//L +   store i32 %37, ptr %8, align 4
//L +   %38 = call signext i42 @r9()
//L +   %39 = sext i42 %38 to i64
//L +   store i64 %39, ptr %9, align 8
//L +   %40 = call i64 @r10()
//L +   store i64 %40, ptr %10, align 8
//L +   %41 = call { i64, i64 } @r11()
//L +   %42 = extractvalue { i64, i64 } %41, 0
//L +   %43 = extractvalue { i64, i64 } %41, 1
//L +   store i64 %42, ptr %22, align 8
//L +   %44 = getelementptr inbounds nuw i8, ptr %22, i32 8
//L +   store i64 %43, ptr %44, align 8
//L +   %45 = load i128, ptr %22, align 8
//L +   %46 = trunc i128 %45 to i65
//L +   %47 = sext i65 %46 to i128
//L +   store i128 %47, ptr %11, align 8
//L +   %48 = call { i64, i64 } @r12()
//L +   %49 = extractvalue { i64, i64 } %48, 0
//L +   %50 = extractvalue { i64, i64 } %48, 1
//L +   store i64 %49, ptr %23, align 8
//L +   %51 = getelementptr inbounds nuw i8, ptr %23, i32 8
//L +   store i64 %50, ptr %51, align 8
//L +   %52 = load i128, ptr %23, align 8
//L +   %53 = trunc i128 %52 to i111
//L +   %54 = sext i111 %53 to i128
//L +   store i128 %54, ptr %12, align 8
//L +   %55 = call i128 @r13()
//L +   store i128 %55, ptr %13, align 16
//L +   call void @r14(ptr sret([24 x i8]) %24)
//L +   %56 = load i192, ptr %24, align 8
//L +   %57 = trunc i192 %56 to i129
//L +   %58 = sext i129 %57 to i192
//L +   store i192 %58, ptr %14, align 8
//L +   %59 = call i32 @r15()
//L +   store i32 %59, ptr %15, align 4
//L +   %60 = call i64 @r16()
//L +   store i64 %60, ptr %16, align 8
//L +   %61 = call { i64, i64 } @r17()
//L +   %62 = extractvalue { i64, i64 } %61, 0
//L +   %63 = extractvalue { i64, i64 } %61, 1
//L +   store i64 %62, ptr %17, align 8
//L +   %64 = getelementptr inbounds nuw i8, ptr %17, i32 8
//L +   store i64 %63, ptr %64, align 8
//L +   call void @r18(ptr sret([400 x i8]) %18)
//L +   %65 = call i32 @r19()
//L +   store i32 %65, ptr %19, align 4
//L +   %66 = call i16 @r20()
//L +   store i16 %66, ptr %20, align 2
//L +   %67 = call i16 @r21()
//L +   store i16 %67, ptr %21, align 2
//L +   ret void
//L + }
//L +
//L + ; Function Attrs: nounwind
//L + declare zeroext i1 @r1() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare signext i1 @r2() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare signext i4 @r3() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare signext i7 @r4() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare i8 @r5() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare i16 @r6() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare signext i17 @r7() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare i32 @r8() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare signext i42 @r9() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare i64 @r10() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare { i64, i64 } @r11() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare { i64, i64 } @r12() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare i128 @r13() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare void @r14(ptr sret([24 x i8])) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare i32 @r15() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare i64 @r16() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare { i64, i64 } @r17() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare void @r18(ptr sret([400 x i8])) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare i32 @r19() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare i16 @r20() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare i16 @r21() #0
//L +
//L + ; Function Attrs: nounwind
//L + define private fastcc void @_S6slicesFvE() #0 {
//L +   %1 = alloca i8, i64 16, align 8
//L +   %2 = alloca i8, i64 16, align 8
//L +   %3 = alloca i8, i64 16, align 8
//L +   %4 = alloca i8, i64 16, align 8
//L +   %5 = alloca i8, i64 16, align 8
//L +   %6 = alloca i8, i64 16, align 8
//L +   store ptr @__srcc_str.0, ptr %1, align 8
//L +   %7 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   store i64 1, ptr %7, align 8
//L +   store ptr @__srcc_str.4, ptr %3, align 8
//L +   %8 = getelementptr inbounds nuw i8, ptr %3, i32 8
//L +   store i64 1, ptr %8, align 8
//L +   call fastcc void @s1(ptr @__srcc_str.1, i64 1, ptr @__srcc_str.2, i64 1, ptr @__srcc_str.3, i64 1, ptr byval([16 x i8]) %3)
//L +   %9 = load ptr, ptr %1, align 8
//L +   %10 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %11 = load i64, ptr %10, align 8
//L +   %12 = load ptr, ptr %1, align 8
//L +   %13 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %14 = load i64, ptr %13, align 8
//L +   %15 = load ptr, ptr %1, align 8
//L +   %16 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %17 = load i64, ptr %16, align 8
//L +   %18 = load ptr, ptr %1, align 8
//L +   %19 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %20 = load i64, ptr %19, align 8
//L +   store ptr %18, ptr %4, align 8
//L +   %21 = getelementptr inbounds nuw i8, ptr %4, i32 8
//L +   store i64 %20, ptr %21, align 8
//L +   call fastcc void @s1(ptr %9, i64 %11, ptr %12, i64 %14, ptr %15, i64 %17, ptr byval([16 x i8]) %4)
//L +   %22 = load ptr, ptr %1, align 8
//L +   %23 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %24 = load i64, ptr %23, align 8
//L +   %25 = load ptr, ptr %1, align 8
//L +   %26 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %27 = load i64, ptr %26, align 8
//L +   call fastcc void @s2(ptr dereferenceable(16) %1, ptr %22, i64 %24, ptr dereferenceable(16) %1, ptr %25, i64 %27)
//L +   %28 = load ptr, ptr %1, align 8
//L +   %29 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %30 = load i64, ptr %29, align 8
//L +   %31 = load ptr, ptr %1, align 8
//L +   %32 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %33 = load i64, ptr %32, align 8
//L +   %34 = load ptr, ptr %1, align 8
//L +   %35 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %36 = load i64, ptr %35, align 8
//L +   store ptr %34, ptr %5, align 8
//L +   %37 = getelementptr inbounds nuw i8, ptr %5, i32 8
//L +   store i64 %36, ptr %37, align 8
//L +   %38 = load ptr, ptr %1, align 8
//L +   %39 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %40 = load i64, ptr %39, align 8
//L +   store ptr %38, ptr %6, align 8
//L +   %41 = getelementptr inbounds nuw i8, ptr %6, i32 8
//L +   store i64 %40, ptr %41, align 8
//L +   call fastcc void @s3(ptr dereferenceable(16) %1, ptr %28, i64 %30, ptr dereferenceable(16) %1, ptr %31, i64 %33, ptr byval([16 x i8]) %5, ptr byval([16 x i8]) %6)
//L +   %42 = call fastcc { i64, i64 } @s4()
//L +   %43 = extractvalue { i64, i64 } %42, 0
//L +   %44 = extractvalue { i64, i64 } %42, 1
//L +   store i64 %43, ptr %2, align 8
//L +   %45 = getelementptr inbounds nuw i8, ptr %2, i32 8
//L +   store i64 %44, ptr %45, align 8
//L +   ret void
//L + }
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc void @s1(ptr, i64, ptr, i64, ptr, i64, ptr byval([16 x i8])) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc void @s2(ptr dereferenceable(16), ptr, i64, ptr dereferenceable(16), ptr, i64) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc void @s3(ptr dereferenceable(16), ptr, i64, ptr dereferenceable(16), ptr, i64, ptr byval([16 x i8]), ptr byval([16 x i8])) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc { i64, i64 } @s4() #0
//L +
//L + ; Function Attrs: nounwind
//L + define private fastcc void @_S8closuresFvE() #0 {
//L +   %1 = alloca i8, i64 16, align 8
//L +   %2 = alloca i8, i64 16, align 8
//L +   %3 = alloca i8, i64 16, align 8
//L +   %4 = alloca i8, i64 16, align 8
//L +   %5 = alloca i8, i64 16, align 8
//L +   %6 = alloca i8, i64 16, align 8
//L +   store ptr @cx, ptr %1, align 8
//L +   %7 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   store ptr null, ptr %7, align 8
//L +   store ptr @cx, ptr %3, align 8
//L +   %8 = getelementptr inbounds nuw i8, ptr %3, i32 8
//L +   store ptr null, ptr %8, align 8
//L +   call fastcc void @c1(ptr @cx, ptr null, ptr @cx, ptr null, ptr @cx, ptr null, ptr byval([16 x i8]) %3)
//L +   %9 = load ptr, ptr %1, align 8
//L +   %10 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %11 = load ptr, ptr %10, align 8
//L +   %12 = load ptr, ptr %1, align 8
//L +   %13 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %14 = load ptr, ptr %13, align 8
//L +   %15 = load ptr, ptr %1, align 8
//L +   %16 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %17 = load ptr, ptr %16, align 8
//L +   %18 = load ptr, ptr %1, align 8
//L +   %19 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %20 = load ptr, ptr %19, align 8
//L +   store ptr %18, ptr %4, align 8
//L +   %21 = getelementptr inbounds nuw i8, ptr %4, i32 8
//L +   store ptr %20, ptr %21, align 8
//L +   call fastcc void @c1(ptr %9, ptr %11, ptr %12, ptr %14, ptr %15, ptr %17, ptr byval([16 x i8]) %4)
//L +   %22 = load ptr, ptr %1, align 8
//L +   %23 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %24 = load ptr, ptr %23, align 8
//L +   %25 = load ptr, ptr %1, align 8
//L +   %26 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %27 = load ptr, ptr %26, align 8
//L +   call fastcc void @c2(ptr dereferenceable(16) %1, ptr %22, ptr %24, ptr dereferenceable(16) %1, ptr %25, ptr %27)
//L +   %28 = load ptr, ptr %1, align 8
//L +   %29 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %30 = load ptr, ptr %29, align 8
//L +   %31 = load ptr, ptr %1, align 8
//L +   %32 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %33 = load ptr, ptr %32, align 8
//L +   %34 = load ptr, ptr %1, align 8
//L +   %35 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %36 = load ptr, ptr %35, align 8
//L +   store ptr %34, ptr %5, align 8
//L +   %37 = getelementptr inbounds nuw i8, ptr %5, i32 8
//L +   store ptr %36, ptr %37, align 8
//L +   %38 = load ptr, ptr %1, align 8
//L +   %39 = getelementptr inbounds nuw i8, ptr %1, i32 8
//L +   %40 = load ptr, ptr %39, align 8
//L +   store ptr %38, ptr %6, align 8
//L +   %41 = getelementptr inbounds nuw i8, ptr %6, i32 8
//L +   store ptr %40, ptr %41, align 8
//L +   call fastcc void @c3(ptr dereferenceable(16) %1, ptr %28, ptr %30, ptr dereferenceable(16) %1, ptr %31, ptr %33, ptr byval([16 x i8]) %5, ptr byval([16 x i8]) %6)
//L +   %42 = call fastcc { i64, i64 } @c4()
//L +   %43 = extractvalue { i64, i64 } %42, 0
//L +   %44 = extractvalue { i64, i64 } %42, 1
//L +   store i64 %43, ptr %2, align 8
//L +   %45 = getelementptr inbounds nuw i8, ptr %2, i32 8
//L +   store i64 %44, ptr %45, align 8
//L +   ret void
//L + }
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc void @cx() #0
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc void @c1(ptr, ptr, ptr, ptr, ptr, ptr, ptr byval([16 x i8])) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc void @c2(ptr dereferenceable(16), ptr, ptr, ptr dereferenceable(16), ptr, ptr) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc void @c3(ptr dereferenceable(16), ptr, ptr, ptr dereferenceable(16), ptr, ptr, ptr byval([16 x i8]), ptr byval([16 x i8])) #0
//L +
//L + ; Function Attrs: nounwind
//L + declare fastcc { i64, i64 } @c4() #0
//L +
//L + ; Function Attrs: nocallback nofree nounwind willreturn memory(argmem: readwrite)
//L + declare void @llvm.memcpy.p0.p0.i64(ptr noalias writeonly captures(none), ptr noalias readonly captures(none), i64, i1 immarg) #1
//L +
//L + ; Function Attrs: nocallback nofree nounwind willreturn memory(argmem: write)
//L + declare void @llvm.memset.p0.i64(ptr writeonly captures(none), i8, i64, i1 immarg) #2
//L +
//L + attributes #0 = { nounwind }
//L + attributes #1 = { nocallback nofree nounwind willreturn memory(argmem: readwrite) }
//L + attributes #2 = { nocallback nofree nounwind willreturn memory(argmem: write) }
//L +
//L + !llvm.module.flags = !{!0}
//L +
//L + !0 = !{i32 2, !"Debug Info Version", i32 3}
