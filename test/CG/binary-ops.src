// R %srcc --ir --short-filenames --target x86_64-unknown-linux %s
program test;

proc sink (in int) {}
proc sink (in bool) {}

proc arith_checked (in int a, in int b) {
    sink(a + b);
    sink(a - b);
    sink(a * b);

    sink(a / b);
    sink(a % b);
    sink(a :/ b);
    sink(a :% b);

    sink(a << b);
    sink(a <<< b);
}

proc arith (in int a, in int b) {
    sink(a +~ b);
    sink(a -~ b);
    sink(a *~ b);

    sink(a >> b);
    sink(a >>> b);

    sink(a & b);
    sink(a | b);

    sink(a < b);
    sink(a <= b);
    sink(a > b);
    sink(a >= b);

    sink(a <: b);
    sink(a <=: b);
    sink(a :> b);
    sink(a :>= b);

    sink(a == b);
    sink(a != b);
}

// * @0 = "<<<\00"
// + @1 = "shift amount exceeds bit width\00"
// + @2 = "<<\00"
// + @3 = ":%\00"
// + @4 = ":/\00"
// + @5 = "%\00"
// + @6 = "division by zero\00"
// + @7 = "/\00"
// + @8 = "*\00"
// + @9 = "-\00"
// + @10 = "binary-ops.src\00"
// + @11 = "integer overflow\00"
// + @12 = "+\00"
// +
// + proc __src_main external fastcc {
// + entry:
// +     ret
// + }
// +
// + proc _S4sinkFvxiE (i64 %0) private fastcc {
// +     #0 = 8, align 8
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     ret
// + }
// +
// + proc _S4sinkFvxbE (i1 %0 zeroext) private fastcc {
// +     #0 = 1, align 1
// +
// + entry:
// +     %1 = sext i1 %0 to i8
// +     store #0, i8 %1, align 1
// +     ret
// + }
// +
// + proc _S13arith_checkedFvxixiE (i64 %0, i64 %1) private fastcc {
// +     #0 = 8, align 8
// +     #1 = 8, align 8
// +     #2 = 64, align 8
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     store #1, i64 %1, align 8
// +     %2 = load i64, #0, align 8
// +     %3 = load i64, #1, align 8
// +     %4 = sadd ov i64 %2, %3
// +     br %4:1 to bb1 else bb2
// +
// + bb1:
// +     store #2, ptr @10, align 8
// +     %5 = ptradd #2, 8
// +     store %5, i64 14, align 8
// +     %6 = ptradd #2, 16
// +     store %6, i64 8, align 8
// +     %7 = ptradd #2, 24
// +     store %7, i64 10, align 8
// +     %8 = ptradd #2, 32
// +     store %8, ptr @12, align 8
// +     %9 = ptradd %8, 8
// +     store %9, i64 1, align 8
// +     %10 = ptradd #2, 48
// +     store %10, ptr @11, align 8
// +     %11 = ptradd %10, 8
// +     store %11, i64 16, align 8
// +     abort at loc("binary-ops.src":8:10) arithmetic(ptr #2)
// +
// + bb2:
// +     call fastcc void _S4sinkFvxiE(i64 %4:0)
// +     %12 = load i64, #0, align 8
// +     %13 = load i64, #1, align 8
// +     %14 = ssub ov i64 %12, %13
// +     br %14:1 to bb3 else bb4
// +
// + bb3:
// +     store #2, ptr @10, align 8
// +     %15 = ptradd #2, 8
// +     store %15, i64 14, align 8
// +     %16 = ptradd #2, 16
// +     store %16, i64 9, align 8
// +     %17 = ptradd #2, 24
// +     store %17, i64 10, align 8
// +     %18 = ptradd #2, 32
// +     store %18, ptr @9, align 8
// +     %19 = ptradd %18, 8
// +     store %19, i64 1, align 8
// +     %20 = ptradd #2, 48
// +     store %20, ptr @11, align 8
// +     %21 = ptradd %20, 8
// +     store %21, i64 16, align 8
// +     abort at loc("binary-ops.src":9:10) arithmetic(ptr #2)
// +
// + bb4:
// +     call fastcc void _S4sinkFvxiE(i64 %14:0)
// +     %22 = load i64, #0, align 8
// +     %23 = load i64, #1, align 8
// +     %24 = smul ov i64 %22, %23
// +     br %24:1 to bb5 else bb6
// +
// + bb5:
// +     store #2, ptr @10, align 8
// +     %25 = ptradd #2, 8
// +     store %25, i64 14, align 8
// +     %26 = ptradd #2, 16
// +     store %26, i64 10, align 8
// +     %27 = ptradd #2, 24
// +     store %27, i64 10, align 8
// +     %28 = ptradd #2, 32
// +     store %28, ptr @8, align 8
// +     %29 = ptradd %28, 8
// +     store %29, i64 1, align 8
// +     %30 = ptradd #2, 48
// +     store %30, ptr @11, align 8
// +     %31 = ptradd %30, 8
// +     store %31, i64 16, align 8
// +     abort at loc("binary-ops.src":10:10) arithmetic(ptr #2)
// +
// + bb6:
// +     call fastcc void _S4sinkFvxiE(i64 %24:0)
// +     %32 = load i64, #0, align 8
// +     %33 = load i64, #1, align 8
// +     %34 = icmp eq i64 %33, 0
// +     br %34 to bb7 else bb8
// +
// + bb7:
// +     store #2, ptr @10, align 8
// +     %35 = ptradd #2, 8
// +     store %35, i64 14, align 8
// +     %36 = ptradd #2, 16
// +     store %36, i64 12, align 8
// +     %37 = ptradd #2, 24
// +     store %37, i64 10, align 8
// +     %38 = ptradd #2, 32
// +     store %38, ptr @7, align 8
// +     %39 = ptradd %38, 8
// +     store %39, i64 1, align 8
// +     %40 = ptradd #2, 48
// +     store %40, ptr @6, align 8
// +     %41 = ptradd %40, 8
// +     store %41, i64 16, align 8
// +     abort at loc("binary-ops.src":12:10) arithmetic(ptr #2)
// +
// + bb8:
// +     %42 = icmp eq i64 %32, -9223372036854775808
// +     %43 = icmp eq i64 %33, -1
// +     %44 = and i1 %42, %43
// +     br %44 to bb9 else bb10
// +
// + bb9:
// +     store #2, ptr @10, align 8
// +     %45 = ptradd #2, 8
// +     store %45, i64 14, align 8
// +     %46 = ptradd #2, 16
// +     store %46, i64 12, align 8
// +     %47 = ptradd #2, 24
// +     store %47, i64 10, align 8
// +     %48 = ptradd #2, 32
// +     store %48, ptr @7, align 8
// +     %49 = ptradd %48, 8
// +     store %49, i64 1, align 8
// +     %50 = ptradd #2, 48
// +     store %50, ptr @11, align 8
// +     %51 = ptradd %50, 8
// +     store %51, i64 16, align 8
// +     abort at loc("binary-ops.src":12:10) arithmetic(ptr #2)
// +
// + bb10:
// +     %52 = sdiv i64 %32, %33
// +     call fastcc void _S4sinkFvxiE(i64 %52)
// +     %53 = load i64, #0, align 8
// +     %54 = load i64, #1, align 8
// +     %55 = icmp eq i64 %54, 0
// +     br %55 to bb11 else bb12
// +
// + bb11:
// +     store #2, ptr @10, align 8
// +     %56 = ptradd #2, 8
// +     store %56, i64 14, align 8
// +     %57 = ptradd #2, 16
// +     store %57, i64 13, align 8
// +     %58 = ptradd #2, 24
// +     store %58, i64 10, align 8
// +     %59 = ptradd #2, 32
// +     store %59, ptr @5, align 8
// +     %60 = ptradd %59, 8
// +     store %60, i64 1, align 8
// +     %61 = ptradd #2, 48
// +     store %61, ptr @6, align 8
// +     %62 = ptradd %61, 8
// +     store %62, i64 16, align 8
// +     abort at loc("binary-ops.src":13:10) arithmetic(ptr #2)
// +
// + bb12:
// +     %63 = icmp eq i64 %53, -9223372036854775808
// +     %64 = icmp eq i64 %54, -1
// +     %65 = and i1 %63, %64
// +     br %65 to bb13 else bb14
// +
// + bb13:
// +     store #2, ptr @10, align 8
// +     %66 = ptradd #2, 8
// +     store %66, i64 14, align 8
// +     %67 = ptradd #2, 16
// +     store %67, i64 13, align 8
// +     %68 = ptradd #2, 24
// +     store %68, i64 10, align 8
// +     %69 = ptradd #2, 32
// +     store %69, ptr @5, align 8
// +     %70 = ptradd %69, 8
// +     store %70, i64 1, align 8
// +     %71 = ptradd #2, 48
// +     store %71, ptr @11, align 8
// +     %72 = ptradd %71, 8
// +     store %72, i64 16, align 8
// +     abort at loc("binary-ops.src":13:10) arithmetic(ptr #2)
// +
// + bb14:
// +     %73 = srem i64 %53, %54
// +     call fastcc void _S4sinkFvxiE(i64 %73)
// +     %74 = load i64, #0, align 8
// +     %75 = load i64, #1, align 8
// +     %76 = icmp eq i64 %75, 0
// +     br %76 to bb15 else bb16
// +
// + bb15:
// +     store #2, ptr @10, align 8
// +     %77 = ptradd #2, 8
// +     store %77, i64 14, align 8
// +     %78 = ptradd #2, 16
// +     store %78, i64 14, align 8
// +     %79 = ptradd #2, 24
// +     store %79, i64 10, align 8
// +     %80 = ptradd #2, 32
// +     store %80, ptr @4, align 8
// +     %81 = ptradd %80, 8
// +     store %81, i64 2, align 8
// +     %82 = ptradd #2, 48
// +     store %82, ptr @6, align 8
// +     %83 = ptradd %82, 8
// +     store %83, i64 16, align 8
// +     abort at loc("binary-ops.src":14:10) arithmetic(ptr #2)
// +
// + bb16:
// +     %84 = udiv i64 %74, %75
// +     call fastcc void _S4sinkFvxiE(i64 %84)
// +     %85 = load i64, #0, align 8
// +     %86 = load i64, #1, align 8
// +     %87 = icmp eq i64 %86, 0
// +     br %87 to bb17 else bb18
// +
// + bb17:
// +     store #2, ptr @10, align 8
// +     %88 = ptradd #2, 8
// +     store %88, i64 14, align 8
// +     %89 = ptradd #2, 16
// +     store %89, i64 15, align 8
// +     %90 = ptradd #2, 24
// +     store %90, i64 10, align 8
// +     %91 = ptradd #2, 32
// +     store %91, ptr @3, align 8
// +     %92 = ptradd %91, 8
// +     store %92, i64 2, align 8
// +     %93 = ptradd #2, 48
// +     store %93, ptr @6, align 8
// +     %94 = ptradd %93, 8
// +     store %94, i64 16, align 8
// +     abort at loc("binary-ops.src":15:10) arithmetic(ptr #2)
// +
// + bb18:
// +     %95 = urem i64 %85, %86
// +     call fastcc void _S4sinkFvxiE(i64 %95)
// +     %96 = load i64, #0, align 8
// +     %97 = load i64, #1, align 8
// +     %98 = icmp uge i64 %97, 64
// +     br %98 to bb19 else bb20
// +
// + bb19:
// +     store #2, ptr @10, align 8
// +     %99 = ptradd #2, 8
// +     store %99, i64 14, align 8
// +     %100 = ptradd #2, 16
// +     store %100, i64 17, align 8
// +     %101 = ptradd #2, 24
// +     store %101, i64 10, align 8
// +     %102 = ptradd #2, 32
// +     store %102, ptr @2, align 8
// +     %103 = ptradd %102, 8
// +     store %103, i64 2, align 8
// +     %104 = ptradd #2, 48
// +     store %104, ptr @1, align 8
// +     %105 = ptradd %104, 8
// +     store %105, i64 30, align 8
// +     abort at loc("binary-ops.src":17:10) arithmetic(ptr #2)
// +
// + bb20:
// +     %106 = shl i64 %96, %97
// +     %107 = ashr i64 %96, 63
// +     %108 = ashr i64 %106, 63
// +     %109 = icmp ne i64 %107, %108
// +     br %109 to bb21 else bb22
// +
// + bb21:
// +     store #2, ptr @10, align 8
// +     %110 = ptradd #2, 8
// +     store %110, i64 14, align 8
// +     %111 = ptradd #2, 16
// +     store %111, i64 17, align 8
// +     %112 = ptradd #2, 24
// +     store %112, i64 10, align 8
// +     %113 = ptradd #2, 32
// +     store %113, ptr @2, align 8
// +     %114 = ptradd %113, 8
// +     store %114, i64 2, align 8
// +     %115 = ptradd #2, 48
// +     store %115, ptr @11, align 8
// +     %116 = ptradd %115, 8
// +     store %116, i64 16, align 8
// +     abort at loc("binary-ops.src":17:10) arithmetic(ptr #2)
// +
// + bb22:
// +     call fastcc void _S4sinkFvxiE(i64 %106)
// +     %117 = load i64, #0, align 8
// +     %118 = load i64, #1, align 8
// +     %119 = icmp uge i64 %118, 64
// +     br %119 to bb23 else bb24
// +
// + bb23:
// +     store #2, ptr @10, align 8
// +     %120 = ptradd #2, 8
// +     store %120, i64 14, align 8
// +     %121 = ptradd #2, 16
// +     store %121, i64 18, align 8
// +     %122 = ptradd #2, 24
// +     store %122, i64 10, align 8
// +     %123 = ptradd #2, 32
// +     store %123, ptr @0, align 8
// +     %124 = ptradd %123, 8
// +     store %124, i64 3, align 8
// +     %125 = ptradd #2, 48
// +     store %125, ptr @1, align 8
// +     %126 = ptradd %125, 8
// +     store %126, i64 30, align 8
// +     abort at loc("binary-ops.src":18:10) arithmetic(ptr #2)
// +
// + bb24:
// +     %127 = shl i64 %117, %118
// +     call fastcc void _S4sinkFvxiE(i64 %127)
// +     ret
// + }
// +
// + proc _S5arithFvxixiE (i64 %0, i64 %1) private fastcc {
// +     #0 = 8, align 8
// +     #1 = 8, align 8
// +
// + entry:
// +     store #0, i64 %0, align 8
// +     store #1, i64 %1, align 8
// +     %2 = load i64, #0, align 8
// +     %3 = load i64, #1, align 8
// +     %4 = add i64 %2, %3
// +     call fastcc void _S4sinkFvxiE(i64 %4)
// +     %5 = load i64, #0, align 8
// +     %6 = load i64, #1, align 8
// +     %7 = sub i64 %5, %6
// +     call fastcc void _S4sinkFvxiE(i64 %7)
// +     %8 = load i64, #0, align 8
// +     %9 = load i64, #1, align 8
// +     %10 = mul i64 %8, %9
// +     call fastcc void _S4sinkFvxiE(i64 %10)
// +     %11 = load i64, #0, align 8
// +     %12 = load i64, #1, align 8
// +     %13 = ashr i64 %11, %12
// +     call fastcc void _S4sinkFvxiE(i64 %13)
// +     %14 = load i64, #0, align 8
// +     %15 = load i64, #1, align 8
// +     %16 = lshr i64 %14, %15
// +     call fastcc void _S4sinkFvxiE(i64 %16)
// +     %17 = load i64, #0, align 8
// +     %18 = load i64, #1, align 8
// +     %19 = and i64 %17, %18
// +     call fastcc void _S4sinkFvxiE(i64 %19)
// +     %20 = load i64, #0, align 8
// +     %21 = load i64, #1, align 8
// +     %22 = or i64 %20, %21
// +     call fastcc void _S4sinkFvxiE(i64 %22)
// +     %23 = load i64, #0, align 8
// +     %24 = load i64, #1, align 8
// +     %25 = icmp slt i64 %23, %24
// +     call fastcc void _S4sinkFvxbE(i1 %25 zeroext)
// +     %26 = load i64, #0, align 8
// +     %27 = load i64, #1, align 8
// +     %28 = icmp sle i64 %26, %27
// +     call fastcc void _S4sinkFvxbE(i1 %28 zeroext)
// +     %29 = load i64, #0, align 8
// +     %30 = load i64, #1, align 8
// +     %31 = icmp sgt i64 %29, %30
// +     call fastcc void _S4sinkFvxbE(i1 %31 zeroext)
// +     %32 = load i64, #0, align 8
// +     %33 = load i64, #1, align 8
// +     %34 = icmp sge i64 %32, %33
// +     call fastcc void _S4sinkFvxbE(i1 %34 zeroext)
// +     %35 = load i64, #0, align 8
// +     %36 = load i64, #1, align 8
// +     %37 = icmp ult i64 %35, %36
// +     call fastcc void _S4sinkFvxbE(i1 %37 zeroext)
// +     %38 = load i64, #0, align 8
// +     %39 = load i64, #1, align 8
// +     %40 = icmp ule i64 %38, %39
// +     call fastcc void _S4sinkFvxbE(i1 %40 zeroext)
// +     %41 = load i64, #0, align 8
// +     %42 = load i64, #1, align 8
// +     %43 = icmp ugt i64 %41, %42
// +     call fastcc void _S4sinkFvxbE(i1 %43 zeroext)
// +     %44 = load i64, #0, align 8
// +     %45 = load i64, #1, align 8
// +     %46 = icmp uge i64 %44, %45
// +     call fastcc void _S4sinkFvxbE(i1 %46 zeroext)
// +     %47 = load i64, #0, align 8
// +     %48 = load i64, #1, align 8
// +     %49 = icmp eq i64 %47, %48
// +     call fastcc void _S4sinkFvxbE(i1 %49 zeroext)
// +     %50 = load i64, #0, align 8
// +     %51 = load i64, #1, align 8
// +     %52 = icmp ne i64 %50, %51
// +     call fastcc void _S4sinkFvxbE(i1 %52 zeroext)
// +     ret
// + }
